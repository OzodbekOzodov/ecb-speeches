{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = pd.read_parquet('src/Data/ecb-speeches.parquet')\n",
    "releases = pd.read_csv(\"src/Data/ecb_releases_302.csv\")\n",
    "announcements = pd.read_csv(\"src/Data/policy_announcements.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>Mr. Duisenberg reports on the outcome of the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-09-18</td>\n",
       "      <td>Mr. Duisenberg’s opening statement at the meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-10-12</td>\n",
       "      <td>Mr. Duisenberg speaks on changes in European f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-10-12</td>\n",
       "      <td>Mr. Duisenberg's statement to the European Par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-10-22</td>\n",
       "      <td>Mr. Duisenberg’s opening statement at the pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>Christine Lagarde: 20th anniversary of the ent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>2022-02-17</td>\n",
       "      <td>Christine Lagarde: Introductory statement - Eu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>2022-02-23</td>\n",
       "      <td>Frank Elderson: Prudential pathways to Paris C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>2022-02-23</td>\n",
       "      <td>Frank Elderson: Towards an immersive superviso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>Frank Elderson: Towards a stronger Anti-Money ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2255 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                            content\n",
       "0     1998-07-17  Mr. Duisenberg reports on the outcome of the s...\n",
       "1     1998-09-18  Mr. Duisenberg’s opening statement at the meet...\n",
       "2     1998-10-12  Mr. Duisenberg speaks on changes in European f...\n",
       "3     1998-10-12  Mr. Duisenberg's statement to the European Par...\n",
       "4     1998-10-22  Mr. Duisenberg’s opening statement at the pres...\n",
       "...          ...                                                ...\n",
       "2250  2022-02-15  Christine Lagarde: 20th anniversary of the ent...\n",
       "2251  2022-02-17  Christine Lagarde: Introductory statement - Eu...\n",
       "2252  2022-02-23  Frank Elderson: Prudential pathways to Paris C...\n",
       "2253  2022-02-23  Frank Elderson: Towards an immersive superviso...\n",
       "2254  2022-02-25  Frank Elderson: Towards a stronger Anti-Money ...\n",
       "\n",
       "[2255 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrrrrr}\n",
      "\\toprule\n",
      " & Jan & Feb & Mar & Apr & May & Jun & Jul & Aug & Sep & Oct & Nov & Dec & Total \\\\\n",
      "year &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "1998 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 3 & 2 & 1 & 8 \\\\\n",
      "1999 & 4 & 2 & 4 & 1 & 6 & 5 & 3 & 0 & 4 & 7 & 7 & 3 & 46 \\\\\n",
      "2000 & 3 & 2 & 4 & 3 & 5 & 3 & 3 & 0 & 6 & 7 & 7 & 2 & 45 \\\\\n",
      "2001 & 3 & 4 & 3 & 1 & 6 & 4 & 2 & 0 & 5 & 3 & 5 & 0 & 36 \\\\\n",
      "2002 & 5 & 4 & 5 & 4 & 5 & 2 & 3 & 0 & 3 & 5 & 2 & 2 & 40 \\\\\n",
      "2003 & 1 & 3 & 2 & 3 & 3 & 3 & 3 & 0 & 2 & 3 & 4 & 4 & 31 \\\\\n",
      "2004 & 2 & 6 & 1 & 8 & 7 & 5 & 2 & 1 & 5 & 7 & 6 & 6 & 56 \\\\\n",
      "2005 & 2 & 5 & 6 & 6 & 4 & 10 & 2 & 1 & 3 & 4 & 3 & 5 & 51 \\\\\n",
      "2006 & 3 & 3 & 5 & 5 & 10 & 6 & 5 & 2 & 1 & 6 & 6 & 6 & 58 \\\\\n",
      "2007 & 3 & 4 & 4 & 7 & 7 & 11 & 6 & 3 & 7 & 14 & 10 & 12 & 88 \\\\\n",
      "2008 & 14 & 9 & 10 & 17 & 12 & 11 & 10 & 2 & 21 & 13 & 16 & 14 & 149 \\\\\n",
      "2009 & 11 & 11 & 11 & 11 & 4 & 20 & 8 & 2 & 16 & 9 & 17 & 10 & 130 \\\\\n",
      "2010 & 7 & 6 & 12 & 16 & 11 & 16 & 6 & 1 & 8 & 18 & 13 & 7 & 121 \\\\\n",
      "2011 & 8 & 12 & 11 & 6 & 19 & 19 & 8 & 4 & 12 & 17 & 15 & 8 & 139 \\\\\n",
      "2012 & 1 & 6 & 8 & 12 & 11 & 8 & 5 & 7 & 10 & 14 & 12 & 9 & 103 \\\\\n",
      "2013 & 8 & 11 & 10 & 14 & 14 & 15 & 12 & 4 & 15 & 19 & 16 & 14 & 152 \\\\\n",
      "2014 & 8 & 12 & 9 & 13 & 13 & 9 & 14 & 3 & 20 & 10 & 16 & 3 & 130 \\\\\n",
      "2015 & 12 & 8 & 12 & 15 & 11 & 9 & 6 & 3 & 13 & 17 & 22 & 8 & 136 \\\\\n",
      "2016 & 13 & 12 & 10 & 11 & 12 & 17 & 3 & 2 & 8 & 5 & 14 & 13 & 120 \\\\\n",
      "2017 & 13 & 10 & 18 & 16 & 16 & 12 & 15 & 8 & 20 & 17 & 20 & 4 & 169 \\\\\n",
      "2018 & 8 & 13 & 17 & 6 & 20 & 4 & 15 & 2 & 9 & 14 & 20 & 7 & 135 \\\\\n",
      "2019 & 14 & 13 & 14 & 8 & 10 & 10 & 11 & 2 & 11 & 18 & 21 & 11 & 143 \\\\\n",
      "2020 & 8 & 17 & 11 & 9 & 4 & 5 & 6 & 3 & 10 & 10 & 11 & 5 & 99 \\\\\n",
      "2021 & 1 & 2 & 11 & 7 & 4 & 7 & 7 & 0 & 2 & 2 & 13 & 4 & 60 \\\\\n",
      "2022 & 3 & 7 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 10 \\\\\n",
      "Total & 155 & 182 & 198 & 199 & 214 & 211 & 156 & 50 & 212 & 242 & 278 & 158 & 2255 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def descriptive_statistics_to_latex(df):\n",
    "    # Extract year and month from 'date' column\n",
    "    df['year'] = pd.to_datetime(df['date']).dt.year\n",
    "    df['month'] = pd.to_datetime(df['date']).dt.month\n",
    "    \n",
    "    # Frequency of speeches by month for each year\n",
    "    monthly_count = df.groupby(['year', 'month']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Adding a column for yearly total\n",
    "    monthly_count['Total'] = monthly_count.sum(axis=1)\n",
    "    \n",
    "    # Rename month columns for clarity\n",
    "    month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    monthly_count.columns = month_names + ['Total']\n",
    "    \n",
    "    # Add a row for monthly total\n",
    "    monthly_count.loc['Total', :] = monthly_count.sum(axis=0)\n",
    "    \n",
    "    # Convert the DataFrame to integer type\n",
    "    monthly_count = monthly_count.astype(int)\n",
    "    \n",
    "    # Convert to LaTeX format\n",
    "    latex_output = monthly_count.to_latex()\n",
    "\n",
    "    return latex_output\n",
    "\n",
    "# Assuming speeches is already defined\n",
    "latex_table = descriptive_statistics_to_latex(speeches)\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def consolidate_lines(df):\n",
    "    \"\"\"\n",
    "    Consolidate lines in the content of a dataframe.\n",
    "    If a line does not end with a full stop, it is merged\n",
    "    with the next line, removing unnecessary newline characters.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Dataframe with 'content' column\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Modified dataframe with consolidated lines\n",
    "    \"\"\"\n",
    "    consolidated_data = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        content = row['content']\n",
    "        lines = content.split('\\n')\n",
    "        consolidated_content = \"\"\n",
    "        for i, line in enumerate(lines):\n",
    "            line = line.strip()\n",
    "            if line and (line[-1] in \".!?\" or i == len(lines) - 1):\n",
    "                consolidated_content += line + \" \"  # Append a space after each line\n",
    "            else:\n",
    "                consolidated_content += line + \" \"  # Append a space to separate lines\n",
    "\n",
    "        consolidated_row = row.copy()\n",
    "        consolidated_row['content'] = consolidated_content.strip()\n",
    "        consolidated_data.append(consolidated_row)\n",
    "\n",
    "    # Create new dataframe with consolidated content\n",
    "    new_df = pd.DataFrame(consolidated_data)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def split_paragraphs(df):\n",
    "    \"\"\"\n",
    "    Splits content of dataframe into separate rows. \n",
    "    If a paragraph exceeds 512 words, it is limited to \n",
    "    two nearly equal parts, with the split done at a full stop.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): Dataframe with 'date' and 'content' columns\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Modified dataframe with split content\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        date = row['date']\n",
    "        content = row['content']\n",
    "\n",
    "        # Split content into sentences\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', content)\n",
    "\n",
    "        # Process each sentence\n",
    "        current_part = \"\"\n",
    "        for sentence in sentences:\n",
    "            if len(current_part.split()) + len(sentence.split()) <= 350:\n",
    "                current_part += \" \" + sentence\n",
    "            else:\n",
    "                if current_part.strip():\n",
    "                    data.append([date, current_part.strip()])\n",
    "                current_part = sentence\n",
    "\n",
    "        # Append remaining part if exists\n",
    "        if current_part.strip():\n",
    "            data.append([date, current_part.strip()])\n",
    "\n",
    "    # Create new dataframe\n",
    "    new_df = pd.DataFrame(data, columns=['date', 'content'])\n",
    "\n",
    "    return new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>Mr. Duisenberg reports on the outcome of the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>First, any “growth dividend” resulting from th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>The committees are as follows (listed in alpha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>The Governing Council intends to decide on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>The Governing Council furthermore agreed that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>2022-02-23</td>\n",
       "      <td>And finally, disclosure frameworks and taxonom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19320</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>Frank Elderson: Towards a stronger Anti-Money ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19321</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>The risk of the use of the financial system fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19322</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>This type of measure has so far only been impl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19323</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>While the proposed limit of €10,000 euro does ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19324 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                            content\n",
       "0     1998-07-17  Mr. Duisenberg reports on the outcome of the s...\n",
       "1     1998-07-17  First, any “growth dividend” resulting from th...\n",
       "2     1998-07-17  The committees are as follows (listed in alpha...\n",
       "3     1998-07-17  The Governing Council intends to decide on the...\n",
       "4     1998-07-17  The Governing Council furthermore agreed that ...\n",
       "...          ...                                                ...\n",
       "19319 2022-02-23  And finally, disclosure frameworks and taxonom...\n",
       "19320 2022-02-25  Frank Elderson: Towards a stronger Anti-Money ...\n",
       "19321 2022-02-25  The risk of the use of the financial system fo...\n",
       "19322 2022-02-25  This type of measure has so far only been impl...\n",
       "19323 2022-02-25  While the proposed limit of €10,000 euro does ...\n",
       "\n",
       "[19324 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_consolidated = consolidate_lines(speeches)\n",
    "speeches_consolidated = split_paragraphs(speeches_consolidated)\n",
    "speeches_consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create counts column that counts words in content column of each row\n",
    "speeches_consolidated['counts'] = speeches_consolidated['content'].str.split().str.len()\n",
    "\n",
    "# remove observations with missing values and counts of less than 50\n",
    "speeches_consolidated = speeches_consolidated[(speeches_consolidated['counts']>=20) & (speeches_consolidated['counts']<500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>Mr. Duisenberg reports on the outcome of the s...</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>First, any “growth dividend” resulting from th...</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>The committees are as follows (listed in alpha...</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>The Governing Council intends to decide on the...</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>The Governing Council furthermore agreed that ...</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>2022-02-23</td>\n",
       "      <td>And finally, disclosure frameworks and taxonom...</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19320</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>Frank Elderson: Towards a stronger Anti-Money ...</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19321</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>The risk of the use of the financial system fo...</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19322</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>This type of measure has so far only been impl...</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19323</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>While the proposed limit of €10,000 euro does ...</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                            content  counts\n",
       "0     1998-07-17  Mr. Duisenberg reports on the outcome of the s...     340\n",
       "1     1998-07-17  First, any “growth dividend” resulting from th...     345\n",
       "2     1998-07-17  The committees are as follows (listed in alpha...     344\n",
       "3     1998-07-17  The Governing Council intends to decide on the...     321\n",
       "4     1998-07-17  The Governing Council furthermore agreed that ...     347\n",
       "...          ...                                                ...     ...\n",
       "19319 2022-02-23  And finally, disclosure frameworks and taxonom...     307\n",
       "19320 2022-02-25  Frank Elderson: Towards a stronger Anti-Money ...     313\n",
       "19321 2022-02-25  The risk of the use of the financial system fo...     331\n",
       "19322 2022-02-25  This type of measure has so far only been impl...     332\n",
       "19323 2022-02-25  While the proposed limit of €10,000 euro does ...      69\n",
       "\n",
       "[19250 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Define the tokenizer\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ozodbek/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2023-09-02 11:43:02.695477: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n\u001b[1;32m      2\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39mpunkt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\n\u001b[1;32m      7\u001b[0m classifier \u001b[39m=\u001b[39m pipeline(\n\u001b[1;32m      8\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtext-classification\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdistilbert-base-uncased-finetuned-sst-2-english\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     tokenizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdistilbert-base-uncased\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1039\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/master_thesis_env/lib/python3.8/site-packages/transformers/utils/import_utils.py:1076\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(name)\n\u001b[1;32m   1075\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m-> 1076\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_class_to_module[name])\n\u001b[1;32m   1077\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1078\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/master_thesis_env/lib/python3.8/site-packages/transformers/utils/import_utils.py:1086\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_module\u001b[39m(\u001b[39mself\u001b[39m, module_name: \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1085\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1086\u001b[0m         \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m   1087\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1088\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1089\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1091\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/master_thesis_env/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m~/anaconda3/envs/master_thesis_env/lib/python3.8/site-packages/transformers/pipelines/__init__.py:44\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenization_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m PreTrainedTokenizer\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     36\u001b[0m     HUGGINGFACE_CO_RESOLVE_ENDPOINT,\n\u001b[1;32m     37\u001b[0m     is_kenlm_available,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     logging,\n\u001b[1;32m     43\u001b[0m )\n\u001b[0;32m---> 44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maudio_classification\u001b[39;00m \u001b[39mimport\u001b[39;00m AudioClassificationPipeline\n\u001b[1;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautomatic_speech_recognition\u001b[39;00m \u001b[39mimport\u001b[39;00m AutomaticSpeechRecognitionPipeline\n\u001b[1;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m     ArgumentHandler,\n\u001b[1;32m     48\u001b[0m     CsvPipelineDataFormat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     infer_framework_load_model,\n\u001b[1;32m     57\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/master_thesis_env/lib/python3.8/site-packages/transformers/pipelines/audio_classification.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m add_end_docstrings, is_torch_available, logging\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m PIPELINE_INIT_ARGS, Pipeline\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m is_torch_available():\n\u001b[1;32m     25\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_auto\u001b[39;00m \u001b[39mimport\u001b[39;00m MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING\n",
      "File \u001b[0;32m~/anaconda3/envs/master_thesis_env/lib/python3.8/site-packages/transformers/pipelines/base.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_extraction_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m PreTrainedFeatureExtractor\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage_processing_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseImageProcessor\n\u001b[0;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodelcard\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelCard\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfiguration_auto\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoConfig\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenization_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m PreTrainedTokenizer\n",
      "File \u001b[0;32m~/anaconda3/envs/master_thesis_env/lib/python3.8/site-packages/transformers/modelcard.py:48\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_auto\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES,\n\u001b[1;32m     34\u001b[0m     MODEL_FOR_CAUSAL_LM_MAPPING_NAMES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING_NAMES,\n\u001b[1;32m     47\u001b[0m )\n\u001b[0;32m---> 48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtraining_args\u001b[39;00m \u001b[39mimport\u001b[39;00m ParallelMode\n\u001b[1;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     50\u001b[0m     MODEL_CARD_NAME,\n\u001b[1;32m     51\u001b[0m     cached_file,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     logging,\n\u001b[1;32m     58\u001b[0m )\n\u001b[1;32m     61\u001b[0m TASK_MAPPING \u001b[39m=\u001b[39m {\n\u001b[1;32m     62\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtext-generation\u001b[39m\u001b[39m\"\u001b[39m: MODEL_FOR_CAUSAL_LM_MAPPING_NAMES,\n\u001b[1;32m     63\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimage-classification\u001b[39m\u001b[39m\"\u001b[39m: MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mzero-shot-image-classification\u001b[39m\u001b[39m\"\u001b[39m: MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING_NAMES,\n\u001b[1;32m     75\u001b[0m }\n",
      "File \u001b[0;32m~/anaconda3/envs/master_thesis_env/lib/python3.8/site-packages/transformers/training_args.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpackaging\u001b[39;00m \u001b[39mimport\u001b[39;00m version\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdebug_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m DebugOption\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtrainer_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     31\u001b[0m     EvaluationStrategy,\n\u001b[1;32m     32\u001b[0m     FSDPOption,\n\u001b[1;32m     33\u001b[0m     HubStrategy,\n\u001b[1;32m     34\u001b[0m     IntervalStrategy,\n\u001b[1;32m     35\u001b[0m     SchedulerType,\n\u001b[1;32m     36\u001b[0m     ShardedDDPOption,\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m     ExplicitEnum,\n\u001b[1;32m     40\u001b[0m     cached_property,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     requires_backends,\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     55\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_optimum_neuron_available\n",
      "File \u001b[0;32m~/anaconda3/envs/master_thesis_env/lib/python3.8/site-packages/transformers/trainer_utils.py:47\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m is_tf_available():\n\u001b[0;32m---> 47\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mseed_worker\u001b[39m(_):\n\u001b[1;32m     51\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39m    Helper function to set worker seed during Dataloader initialization.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/master_thesis_env/lib/python3.8/site-packages/tensorflow/__init__.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     41\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/master_thesis_env/lib/python3.8/site-packages/tensorflow/python/__init__.py:36\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtraceback\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/master_thesis_env/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py:26\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m self_check\n\u001b[1;32m     23\u001b[0m \u001b[39m# TODO(mdan): Cleanup antipattern: import for side effects.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[39m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m self_check\u001b[39m.\u001b[39;49mpreload_check()\n\u001b[1;32m     28\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m   \u001b[39m# This import is expected to fail if there is an explicit shared object\u001b[39;00m\n\u001b[1;32m     32\u001b[0m   \u001b[39m# dependency (with_framework_lib=true), since we do not need RTLD_GLOBAL.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/master_thesis_env/lib/python3.8/site-packages/tensorflow/python/platform/self_check.py:63\u001b[0m, in \u001b[0;36mpreload_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     51\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mCould not find the DLL(s) \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m. TensorFlow requires that these DLLs \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mbe installed in a directory that is named in your \u001b[39m\u001b[39m%%\u001b[39;00m\u001b[39mPATH\u001b[39m\u001b[39m%%\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mhttps://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m           \u001b[39m%\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m or \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(missing))\n\u001b[1;32m     58\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m   \u001b[39m# Load a library that performs CPU feature guard checking.  Doing this here\u001b[39;00m\n\u001b[1;32m     60\u001b[0m   \u001b[39m# as a preload check makes it more likely that we detect any CPU feature\u001b[39;00m\n\u001b[1;32m     61\u001b[0m   \u001b[39m# incompatibilities before we trigger them (which would typically result in\u001b[39;00m\n\u001b[1;32m     62\u001b[0m   \u001b[39m# SIGILL).\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_cpu_feature_guard\n\u001b[1;32m     64\u001b[0m   _pywrap_cpu_feature_guard\u001b[39m.\u001b[39mInfoAboutUnusedCPUFeatures()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from transformers import pipeline\n",
    "\n",
    "import transformers\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    tokenizer=\"distilbert-base-uncased\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  positive  negative\n",
      "0  Mr. Duisenberg reports on the outcome of the s...  0.988099  0.011901\n",
      "1  The general picture is one of continued econom...  0.960844  0.039156\n",
      "2  As far as pricedevelopments are concerned, inf...  0.997458  0.002542\n",
      "3  Economic growth has been driven increasingly b...  0.787363  0.212637\n",
      "4  The favourable conjunctural situation has star...  0.815906  0.184094\n",
      "5  As regards monetary and financial developments...  0.687710  0.312290\n",
      "6  In principle, the economic performance I have ...  0.531834  0.468166\n",
      "7  In this respect, I should like to underline th...  0.998245  0.001755\n",
      "8  Second, most Member States need togo a step fu...  0.928188  0.071812\n",
      "9  This implies that the benchmark for fiscalpoli...  0.995707  0.004293\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functions import calculate_sentiment_distilbert\n",
    "\n",
    "max_chunk_length = 512\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# add content\n",
    "df['content'] = speeches_consolidated['content'].head(10)\n",
    "\n",
    "# Apply the sentiment analysis function to the 'content' column for the first 10 rows\n",
    "df[['positive', 'negative']] = speeches_consolidated['content'].head(10).apply(\n",
    "    lambda x: pd.Series(calculate_sentiment_distilbert(x))\n",
    ")\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date                                            content  positive  \\\n",
      "544 2008-09-03  Gertrude Tumpel-Gugerell: Start of the ECB/ESC...  0.983223   \n",
      "545 2008-09-04  Gertrude Tumpel-Gugerell: Moving ahead with th...  0.976558   \n",
      "546 2008-09-09  European Central Bank: Press conference – intr...  0.903439   \n",
      "547 2008-09-09  Jürgen Stark: Monetary policy during the finan...  0.945200   \n",
      "548 2008-09-09  Jean-Claude Trichet: Risk and the macro-econom...  0.931020   \n",
      "549 2008-09-09  José Manuel González-Páramo: Globalisation, ma...  0.932746   \n",
      "550 2008-09-10  Jürgen Stark: Economic perspectives and moneta...  0.931714   \n",
      "551 2008-09-10  Gertrude Tumpel-Gugerell: What is the role of ...  0.976124   \n",
      "552 2008-09-11  José Manuel González-Páramo: Some lessons from...  0.939504   \n",
      "553 2008-09-11  Jean Claude-Trichet: Hearing before the Econom...  0.889569   \n",
      "554 2008-09-11  Gertrude Tumpel-Gugerell: SEPA for cards\\nSpee...  0.900189   \n",
      "555 2008-09-15  Gertrude Tumpel-Gugerell: EU priorities for in...  0.954767   \n",
      "556 2008-09-15  Jean-Claude Trichet: The European Regulatory a...  0.946417   \n",
      "557 2008-09-17  Jean-Claude Trichet: Ehrenplaquette of the cit...  0.943632   \n",
      "558 2008-09-17  Gertrude Tumpel-Gugerell: Priorities for EU in...  0.906066   \n",
      "559 2008-09-17  Lucas Papademos: China and the European Union ...  0.964078   \n",
      "560 2008-09-23  Jean-Claude Trichet: Inauguration of the “Euro...  0.992300   \n",
      "561 2008-09-24  Jean-Claude Trichet: The entry of Slovakia int...  0.945500   \n",
      "562 2008-09-25  Jean-Claude Trichet: Interview with Hospodársk...  0.880834   \n",
      "563 2008-09-30  Lorenzo Bini Smaghi: Celebrating 50 years of E...  0.961880   \n",
      "564 2008-09-30  José Manuel González-Páramo: Central banks and...  0.926179   \n",
      "\n",
      "     negative  \n",
      "544  0.016777  \n",
      "545  0.023442  \n",
      "546  0.096561  \n",
      "547  0.054800  \n",
      "548  0.068980  \n",
      "549  0.067254  \n",
      "550  0.068286  \n",
      "551  0.023876  \n",
      "552  0.060496  \n",
      "553  0.110431  \n",
      "554  0.099811  \n",
      "555  0.045233  \n",
      "556  0.053583  \n",
      "557  0.056368  \n",
      "558  0.093934  \n",
      "559  0.035922  \n",
      "560  0.007700  \n",
      "561  0.054500  \n",
      "562  0.119166  \n",
      "563  0.038120  \n",
      "564  0.073821  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6673/2830050635.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[['positive', 'negative']] = subset_df['content'].apply(lambda x: pd.Series(calculate_sentiment_distilbert(x)))\n",
      "/tmp/ipykernel_6673/2830050635.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[['positive', 'negative']] = subset_df['content'].apply(lambda x: pd.Series(calculate_sentiment_distilbert(x)))\n"
     ]
    }
   ],
   "source": [
    "# Define the start and end dates of the desired date range\n",
    "start_date = '2008-09-01'\n",
    "end_date = '2008-09-30'\n",
    "\n",
    "# Filter the DataFrame based on the date range\n",
    "subset_df = speeches[(speeches['date'] >= start_date) & (speeches['date'] <= end_date)]\n",
    "\n",
    "# Apply the sentiment analysis function to the 'content' column for the subset\n",
    "subset_df[['positive', 'negative']] = subset_df['content'].apply(lambda x: pd.Series(calculate_sentiment_distilbert(x)))\n",
    "\n",
    "# Print the updated subset DataFrame\n",
    "print(subset_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speeches with FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')\n",
    "model = BertForSequenceClassification.from_pretrained('ProsusAI/finbert')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "sentiment = pipe(text)\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6673/1113428978.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset[['positive', 'negative']] = subset['content'].head(10).apply(lambda x: pd.Series(calculate_sentiment_finbert(x)))\n",
      "/tmp/ipykernel_6673/1113428978.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset[['positive', 'negative']] = subset['content'].head(10).apply(lambda x: pd.Series(calculate_sentiment_finbert(x)))\n",
      "/tmp/ipykernel_6673/1113428978.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['neutral'] = 1 - subset['positive'] - subset['negative']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>counts</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>Mr. Duisenberg reports on the outcome of the s...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.937748</td>\n",
       "      <td>0.041710</td>\n",
       "      <td>0.020542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>The general picture is one of continued econom...</td>\n",
       "      <td>34</td>\n",
       "      <td>0.034190</td>\n",
       "      <td>0.034694</td>\n",
       "      <td>0.931116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>As far as pricedevelopments are concerned, inf...</td>\n",
       "      <td>49</td>\n",
       "      <td>0.030530</td>\n",
       "      <td>0.951551</td>\n",
       "      <td>0.017919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>Economic growth has been driven increasingly b...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.883557</td>\n",
       "      <td>0.097784</td>\n",
       "      <td>0.018659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>The favourable conjunctural situation has star...</td>\n",
       "      <td>49</td>\n",
       "      <td>0.101933</td>\n",
       "      <td>0.880079</td>\n",
       "      <td>0.017988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>As regards monetary and financial developments...</td>\n",
       "      <td>49</td>\n",
       "      <td>0.447888</td>\n",
       "      <td>0.532956</td>\n",
       "      <td>0.019157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>In principle, the economic performance I have ...</td>\n",
       "      <td>45</td>\n",
       "      <td>0.489348</td>\n",
       "      <td>0.406243</td>\n",
       "      <td>0.104409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>In this respect, I should like to underline th...</td>\n",
       "      <td>34</td>\n",
       "      <td>0.719490</td>\n",
       "      <td>0.179986</td>\n",
       "      <td>0.100524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>Second, most Member States need togo a step fu...</td>\n",
       "      <td>29</td>\n",
       "      <td>0.036569</td>\n",
       "      <td>0.946498</td>\n",
       "      <td>0.016933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>This implies that the benchmark for fiscalpoli...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.324513</td>\n",
       "      <td>0.065784</td>\n",
       "      <td>0.609703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                            content  counts  \\\n",
       "0 1998-07-17  Mr. Duisenberg reports on the outcome of the s...      50   \n",
       "1 1998-07-17  The general picture is one of continued econom...      34   \n",
       "2 1998-07-17  As far as pricedevelopments are concerned, inf...      49   \n",
       "3 1998-07-17  Economic growth has been driven increasingly b...      35   \n",
       "4 1998-07-17  The favourable conjunctural situation has star...      49   \n",
       "5 1998-07-17  As regards monetary and financial developments...      49   \n",
       "6 1998-07-17  In principle, the economic performance I have ...      45   \n",
       "7 1998-07-17  In this respect, I should like to underline th...      34   \n",
       "8 1998-07-17  Second, most Member States need togo a step fu...      29   \n",
       "9 1998-07-17  This implies that the benchmark for fiscalpoli...      30   \n",
       "\n",
       "   positive  negative   neutral  \n",
       "0  0.937748  0.041710  0.020542  \n",
       "1  0.034190  0.034694  0.931116  \n",
       "2  0.030530  0.951551  0.017919  \n",
       "3  0.883557  0.097784  0.018659  \n",
       "4  0.101933  0.880079  0.017988  \n",
       "5  0.447888  0.532956  0.019157  \n",
       "6  0.489348  0.406243  0.104409  \n",
       "7  0.719490  0.179986  0.100524  \n",
       "8  0.036569  0.946498  0.016933  \n",
       "9  0.324513  0.065784  0.609703  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting with press releases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with press releases\n",
    "import pandas as pd\n",
    "press_releases = pd.read_csv(\"src/data/ecb_releases_302.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-08-2023</td>\n",
       "      <td>10 August 2023 Europa Open Air 2023 celebrates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-07-2023</td>\n",
       "      <td>5 July 2023 Compared with April 2023: consumer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04-07-2023</td>\n",
       "      <td>4 July 2023 Credit terms and conditions tighte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28-06-2023</td>\n",
       "      <td>28 June 2023 Proposed legislation establishes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22-06-2023</td>\n",
       "      <td>22 June 2023 The aggregate of total assets of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>18-09-1998</td>\n",
       "      <td>The European Central Bank (ECB) will today pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>18-09-1998</td>\n",
       "      <td>The Headquarters Agreement between the Governm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>In accordance with the Resolution adopted by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>Given that the euro banknotes will be put into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>In addition to its meetings scheduled for 13 O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                            content\n",
       "0    10-08-2023  10 August 2023 Europa Open Air 2023 celebrates...\n",
       "1    05-07-2023  5 July 2023 Compared with April 2023: consumer...\n",
       "2    04-07-2023  4 July 2023 Credit terms and conditions tighte...\n",
       "3    28-06-2023  28 June 2023 Proposed legislation establishes ...\n",
       "4    22-06-2023  22 June 2023 The aggregate of total assets of ...\n",
       "..          ...                                                ...\n",
       "297  18-09-1998  The European Central Bank (ECB) will today pub...\n",
       "298  18-09-1998  The Headquarters Agreement between the Governm...\n",
       "299  12-09-1998  In accordance with the Resolution adopted by t...\n",
       "300  12-09-1998  Given that the euro banknotes will be put into...\n",
       "301  12-09-1998  In addition to its meetings scheduled for 13 O...\n",
       "\n",
       "[302 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Convert date column to datetime format\n",
    "press_releases['date'] = pd.to_datetime(press_releases['date'], format='%d %B %Y')\n",
    "\n",
    "# Convert date to \"DD-MM-YYYY\" format\n",
    "press_releases['date'] = press_releases['date'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# Remove new line characters, replace with space\n",
    "press_releases['content'] = press_releases['content'].str.replace('\\n', ' ')\n",
    "\n",
    "press_releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_paragraphs(df):\n",
    "    \"\"\"\n",
    "    Splits content of dataframe into separate rows. \n",
    "    If a paragraph exceeds 512 words, it is limited to \n",
    "    two nearly equal parts, with the split done at a full stop.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): Dataframe with 'date' and 'content' columns\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Modified dataframe with split content\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        date = row['date']\n",
    "        content = row['content']\n",
    "\n",
    "        # Split content into sentences\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', content)\n",
    "\n",
    "        # Process each sentence\n",
    "        current_part = \"\"\n",
    "        for sentence in sentences:\n",
    "            if len(current_part.split()) + len(sentence.split()) <= 150:\n",
    "                current_part += \" \" + sentence\n",
    "            else:\n",
    "                if current_part.strip():\n",
    "                    data.append([date, current_part.strip()])\n",
    "                current_part = sentence\n",
    "\n",
    "        # Append remaining part if exists\n",
    "        if current_part.strip():\n",
    "            data.append([date, current_part.strip()])\n",
    "\n",
    "    # Create new dataframe\n",
    "    new_df = pd.DataFrame(data, columns=['date', 'content'])\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-08-2023</td>\n",
       "      <td>10 August 2023 Europa Open Air 2023 celebrates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-08-2023</td>\n",
       "      <td>The evening will start with a performance by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05-07-2023</td>\n",
       "      <td>5 July 2023 Compared with April 2023: consumer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05-07-2023</td>\n",
       "      <td>Uncertainty about inflation expectations 12 mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-07-2023</td>\n",
       "      <td>Expectations for nominal spending growth over ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>In line with the Resolution of the European Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>Given that the euro banknotes will be put into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>In addition to its meetings scheduled for 13 O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>As a result, the schedule for the meetings of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>The schedule for meetings of the General Counc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                            content\n",
       "0     10-08-2023  10 August 2023 Europa Open Air 2023 celebrates...\n",
       "1     10-08-2023  The evening will start with a performance by t...\n",
       "2     05-07-2023  5 July 2023 Compared with April 2023: consumer...\n",
       "3     05-07-2023  Uncertainty about inflation expectations 12 mo...\n",
       "4     05-07-2023  Expectations for nominal spending growth over ...\n",
       "...          ...                                                ...\n",
       "1008  12-09-1998  In line with the Resolution of the European Co...\n",
       "1009  12-09-1998  Given that the euro banknotes will be put into...\n",
       "1010  12-09-1998  In addition to its meetings scheduled for 13 O...\n",
       "1011  12-09-1998  As a result, the schedule for the meetings of ...\n",
       "1012  12-09-1998  The schedule for meetings of the General Counc...\n",
       "\n",
       "[1013 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "press_releases_long = split_paragraphs(press_releases)\n",
    "press_releases_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10 August 2023 Europa Open Air 2023 celebrates Europe’s diversity in Frankfurt Over 12,000 guests expected for musical evening on waterfront On Thursday, 31 August 2023 the European Central Bank (ECB), together with broadcaster Hessischer Rundfunk, will once again present the traditional Europa Open Air concert with the Hessischer Rundfunk orchestra, Frankfurt Radio Symphony. The popular concert at Frankfurt’s waterfront location Weseler Werft will allow spectators to enjoy some of Europe’s finest concert pieces, with “celebrating Europe” as the theme. This year the event coincides with the 25th anniversary of the ECB. “Europa Open Air reflects the ECB’s commitment as a European institution and as a member of the local community. Music, literature and the performing and fine arts know no borders; they allow us to be united in diversity,” said ECB President Christine Lagarde.',\n",
       " 'The evening will start with a performance by the Frankfurt Radio Big Band, accompanied by soul singer Joy Denalane. Conducted by music director Alain Altinoglu, the Frankfurt Radio Symphony will then present pieces based on musical fairy tales. The event will close with two works featuring Mediterranean rhythms. The concert will be broadcast live over the internet, and on German TV and radio. Further information (in German) can be found on Hessischer Rundfunk’s website. For media queries, please contact Verena Reith, tel.: +49 69 1344 5737.',\n",
       " '5 July 2023 Compared with April 2023: consumer inflation expectations for the next 12 months decreased further, while those for inflation three years ahead remained stable; expectations for nominal income growth over the next 12 months increased slightly, while expectations for nominal spending growth continued to decline; expectations for economic growth over the next 12 months became less negative and the expected unemployment rate in 12 months’ time decreased; consumers expect lower growth in the price of their home over the next 12 months and expectations for mortgage interest rates 12 months ahead increased slightly. Inflation The median rate of perceived inflation over the previous 12 months decreased to 8.0% in May 2023, from 8.9% in April. Median expectations for inflation over the next 12 months also decreased to 3.9%, from 4.1% in April, while those for inflation three years ahead remained unchanged at 2.5%.',\n",
       " 'Uncertainty about inflation expectations 12 months ahead fell to its lowest level since March 2022 (after the start of Russia’s war in Ukraine), although it remained above levels observed prior to this. Inflation expectations remained well below the perceived past inflation rate, particularly at the three-year horizon. Inflation perceptions and expectations continued to be closely aligned across income classes, with younger respondents (aged 18-34) still reporting lower inflation perceptions and expectations than older respondents (aged 55-70). (Inflation results) Income and consumption Consumers expected their nominal income over the next 12 months to increase by 1.2%, compared with 1.1% in April. The increase in expected nominal income growth was mainly concentrated in the two lowest quintiles of the income distribution, while consumers’ expectations in the fifth (highest) income quintile decreased, on average. Perceptions of nominal spending growth over the previous 12 months decreased slightly to 6.8%, from 7.0% in April.',\n",
       " 'Expectations for nominal spending growth over the next 12 months decreased further to 3.5%, from 3.8% in April and 4.1% in March. The higher income groups reported a sharper drop in expectations for nominal spending growth than the lower two quintiles of the income distribution. (Income and consumption results) Labour market and economic growth Economic growth expectations for the next 12 months were slightly less negative, standing at -0.7% compared with -0.8% in April. In line with these less negative expectations for economic growth, expectations for the unemployment rate 12 months ahead decreased to 11.0%, from 11.2% in April. Consumers continued to expect the future unemployment rate to be only slightly higher than the perceived current unemployment rate (10.9%), implying a broadly stable labour market. Consumers in the lowest income quintile reported the largest decline in perceived and expected unemployment rates.',\n",
       " '(Labour market and economic growth results) Housing and credit access Consumers expected the price of their home to increase by 2.1% over the next 12 months – the lowest value reported in the past two years – compared with 2.2% in April. The decline in expectations was driven by respondents aged 55 to 70 and was broad-based across income categories, with the noticeable exception of the lowest income quintile. Expectations for mortgage interest rates 12 months ahead edged up to 5.1%, from 5.0% in April. Perceived access to credit over the previous 12 months and expectations for access to credit over the next 12 months both eased slightly compared with April. (Housing and credit access results) The next release of the CES results is scheduled for 8 August 2023. For media queries, please contact Eszter Miltényi-Torstensson, tel.: +49 171 7695305.',\n",
       " 'Notes Unless otherwise indicated, the statistics given in this press release refer to the 2% winsorised mean. For further details, see the aggregate statistics guide published on the CES webpage. The CES is a monthly online survey of currently around 14,000 adult consumers (i.e. aged 18 or over) from six euro area countries: Belgium, Germany, Spain, France, Italy and the Netherlands. The main aggregate results of the CES are published on the ECB’s website every month. The results are used for policy analysis and complement other data sources used by the ECB. Further information about the survey and the data collected is available on the CES web page. Detailed information can also be found in the following two publications: ECB, “ECB Consumer Expectations Survey: an overview and first evaluation”, Occasional Paper Series, No 287, Frankfurt am Main, December 2021; and Georgarakos, D.',\n",
       " 'and Kenny, G., “Household spending and fiscal support during the COVID-19 pandemic: Insights from a new consumer survey”, Journal of Monetary Economics, Vol. 129, Supplement, July 2022, pp. S1-S14. The survey results do not represent the views of the ECB’s decision-making bodies or staff.',\n",
       " '4 July 2023 Credit terms and conditions tightened for all types of counterparty between March and May 2023 Resources and attention dedicated to managing concentrated credit exposures to banks and dealers increased With the exception of domestic government bonds, financing rates/spreads increased for funding secured against all types of collateral Overall credit terms and conditions in the securities financing and OTC derivatives markets tightened for all types of counterparty between March and May 2023. This was a continuation of the developments observed over the previous eight quarters and was in line with the expectations expressed in the March 2023 survey. The tightening of credit terms and conditions was most pronounced for banks and dealers and insurance companies.',\n",
       " 'Survey respondents mainly attributed this tightening to a deterioration in general market liquidity and functioning – and, to a lesser extent, concerns about an expected deterioration in the financial strength of counterparties and reduced competition from other institutions. Respondents expected overall credit terms to tighten further over the period from June to August 2023. Importantly, 40% of respondents reported that the amount of resources and attention dedicated to managing concentrated credit exposures to banks and dealers had increased over the review period. Chart 1 Changes in overall credit terms and price/non-price terms offered to counterparties across all transaction types (Q2 2022 to Q2 2023; net percentages of survey respondents) Source: ECB. Note: Net percentages are calculated as the difference between the percentage of respondents reporting “tightened somewhat” or “tightened considerably” and the percentage reporting “eased somewhat” or “eased considerably”.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = press_releases_long['content'].head(10).tolist()\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-02 11:43:10.635222: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-02 11:43:18.876548: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'neutral', 'score': 0.743184506893158},\n",
       " {'label': 'neutral', 'score': 0.9470413327217102},\n",
       " {'label': 'negative', 'score': 0.9648347496986389},\n",
       " {'label': 'negative', 'score': 0.9272911548614502},\n",
       " {'label': 'negative', 'score': 0.9685605764389038},\n",
       " {'label': 'positive', 'score': 0.6246066689491272},\n",
       " {'label': 'neutral', 'score': 0.9494417905807495},\n",
       " {'label': 'neutral', 'score': 0.8853647708892822},\n",
       " {'label': 'negative', 'score': 0.7680923342704773},\n",
       " {'label': 'negative', 'score': 0.6854082345962524}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "\n",
    "sentiments = pipe(subset)\n",
    "\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-08-2023</td>\n",
       "      <td>10 August 2023 Europa Open Air 2023 celebrates...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.743185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-08-2023</td>\n",
       "      <td>The evening will start with a performance by t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.947041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05-07-2023</td>\n",
       "      <td>5 July 2023 Compared with April 2023: consumer...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.964835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05-07-2023</td>\n",
       "      <td>Uncertainty about inflation expectations 12 mo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.927291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-07-2023</td>\n",
       "      <td>Expectations for nominal spending growth over ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.968561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>In line with the Resolution of the European Co...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.812149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>Given that the euro banknotes will be put into...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.948980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>In addition to its meetings scheduled for 13 O...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.942333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>As a result, the schedule for the meetings of ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.931692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>The schedule for meetings of the General Counc...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.918103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                            content sentiment  \\\n",
       "0     10-08-2023  10 August 2023 Europa Open Air 2023 celebrates...   neutral   \n",
       "1     10-08-2023  The evening will start with a performance by t...   neutral   \n",
       "2     05-07-2023  5 July 2023 Compared with April 2023: consumer...  negative   \n",
       "3     05-07-2023  Uncertainty about inflation expectations 12 mo...  negative   \n",
       "4     05-07-2023  Expectations for nominal spending growth over ...  negative   \n",
       "...          ...                                                ...       ...   \n",
       "1008  12-09-1998  In line with the Resolution of the European Co...   neutral   \n",
       "1009  12-09-1998  Given that the euro banknotes will be put into...   neutral   \n",
       "1010  12-09-1998  In addition to its meetings scheduled for 13 O...   neutral   \n",
       "1011  12-09-1998  As a result, the schedule for the meetings of ...   neutral   \n",
       "1012  12-09-1998  The schedule for meetings of the General Counc...   neutral   \n",
       "\n",
       "      sentiment_score  \n",
       "0            0.743185  \n",
       "1            0.947041  \n",
       "2            0.964835  \n",
       "3            0.927291  \n",
       "4            0.968561  \n",
       "...               ...  \n",
       "1008         0.812149  \n",
       "1009         0.948980  \n",
       "1010         0.942333  \n",
       "1011         0.931692  \n",
       "1012         0.918103  \n",
       "\n",
       "[1013 rows x 4 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Create the text classification pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "# Assuming your DataFrame is called press_releases_long\n",
    "subset = press_releases_long['content']  # Select the content column\n",
    "\n",
    "# Create empty lists to store sentiment labels and scores\n",
    "sentiment_labels = []\n",
    "sentiment_scores = []\n",
    "\n",
    "# Perform sentiment analysis using the pipeline and populate the lists\n",
    "for text in subset:\n",
    "    sentiment = pipe(text)[0]\n",
    "    sentiment_labels.append(sentiment['label'])\n",
    "    sentiment_scores.append(sentiment['score'])\n",
    "\n",
    "# press_releases_10 = press_releases_long.head(10)\n",
    "# Add new columns to the DataFrame\n",
    "press_releases_long['sentiment'] = sentiment_labels\n",
    "press_releases_long['sentiment_score'] = sentiment_scores\n",
    "\n",
    "# Display the modified DataFrame\n",
    "press_releases_long.to_csv('src/data/press_releases_baseline_finbert(23.08 - 11:48).csv', index=False)\n",
    "press_releases_long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-08-2023</td>\n",
       "      <td>10 August 2023 Europa Open Air 2023 celebrates...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.743185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-08-2023</td>\n",
       "      <td>The evening will start with a performance by t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.947041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05-07-2023</td>\n",
       "      <td>5 July 2023 Compared with April 2023: consumer...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.964835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05-07-2023</td>\n",
       "      <td>Uncertainty about inflation expectations 12 mo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.927291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-07-2023</td>\n",
       "      <td>Expectations for nominal spending growth over ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.968561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>In line with the Resolution of the European Co...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.812149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>Given that the euro banknotes will be put into...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.948980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>In addition to its meetings scheduled for 13 O...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.942333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>As a result, the schedule for the meetings of ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.931692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>The schedule for meetings of the General Counc...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.918103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                            content sentiment  \\\n",
       "0     10-08-2023  10 August 2023 Europa Open Air 2023 celebrates...   neutral   \n",
       "1     10-08-2023  The evening will start with a performance by t...   neutral   \n",
       "2     05-07-2023  5 July 2023 Compared with April 2023: consumer...  negative   \n",
       "3     05-07-2023  Uncertainty about inflation expectations 12 mo...  negative   \n",
       "4     05-07-2023  Expectations for nominal spending growth over ...  negative   \n",
       "...          ...                                                ...       ...   \n",
       "1008  12-09-1998  In line with the Resolution of the European Co...   neutral   \n",
       "1009  12-09-1998  Given that the euro banknotes will be put into...   neutral   \n",
       "1010  12-09-1998  In addition to its meetings scheduled for 13 O...   neutral   \n",
       "1011  12-09-1998  As a result, the schedule for the meetings of ...   neutral   \n",
       "1012  12-09-1998  The schedule for meetings of the General Counc...   neutral   \n",
       "\n",
       "      sentiment_score  \n",
       "0            0.743185  \n",
       "1            0.947041  \n",
       "2            0.964835  \n",
       "3            0.927291  \n",
       "4            0.968561  \n",
       "...               ...  \n",
       "1008         0.812149  \n",
       "1009         0.948980  \n",
       "1010         0.942333  \n",
       "1011         0.931692  \n",
       "1012         0.918103  \n",
       "\n",
       "[1013 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "press_releases_long = pd.read_csv('src/data/press_releases_baseline_finbert(23.08 - 11:48).csv')\n",
    "press_releases_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2023</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.821764</td>\n",
       "      <td>1 January 2023 Euro banknotes and coins start ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-02-2022</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.764884</td>\n",
       "      <td>Banks had a generally benign view of firms’ an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-02-2022</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.884606</td>\n",
       "      <td>A total of 152 banks were surveyed in this rou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-02-2022</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.749230</td>\n",
       "      <td>1 February 2022 Credit standards tightened sli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-06-2021</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.804409</td>\n",
       "      <td>1 June 2021 SME turnover and profits continued...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>31-05-2023</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.829122</td>\n",
       "      <td>31 May 2023 Tighter financial conditions test ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>31-08-1999</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.875617</td>\n",
       "      <td>The European Central Bank (ECB) is today relea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>31-10-2022</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.740483</td>\n",
       "      <td>Turning to non-centrally cleared over-the coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>31-10-2022</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.943439</td>\n",
       "      <td>31 October 2022 Tighter credit terms and condi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>31-12-1998</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.928008</td>\n",
       "      <td>In accordance with Article 109l (4) of the Tre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date sentiment  sentiment_score  \\\n",
       "0    01-01-2023   neutral         0.821764   \n",
       "1    01-02-2022  negative         0.764884   \n",
       "2    01-02-2022   neutral         0.884606   \n",
       "3    01-02-2022  positive         0.749230   \n",
       "4    01-06-2021  negative         0.804409   \n",
       "..          ...       ...              ...   \n",
       "415  31-05-2023  negative         0.829122   \n",
       "416  31-08-1999   neutral         0.875617   \n",
       "417  31-10-2022   neutral         0.740483   \n",
       "418  31-10-2022  negative         0.943439   \n",
       "419  31-12-1998   neutral         0.928008   \n",
       "\n",
       "                                               content  \n",
       "0    1 January 2023 Euro banknotes and coins start ...  \n",
       "1    Banks had a generally benign view of firms’ an...  \n",
       "2    A total of 152 banks were surveyed in this rou...  \n",
       "3    1 February 2022 Credit standards tightened sli...  \n",
       "4    1 June 2021 SME turnover and profits continued...  \n",
       "..                                                 ...  \n",
       "415  31 May 2023 Tighter financial conditions test ...  \n",
       "416  The European Central Bank (ECB) is today relea...  \n",
       "417  Turning to non-centrally cleared over-the coun...  \n",
       "418  31 October 2022 Tighter credit terms and condi...  \n",
       "419  In accordance with Article 109l (4) of the Tre...  \n",
       "\n",
       "[420 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_df = press_releases_long.groupby(['date', 'sentiment'], as_index=False).agg({\n",
    "    'sentiment_score': 'mean',\n",
    "    'content': ' '.join\n",
    "})\n",
    "aggregated_df = aggregated_df.sort_values(by='date').reset_index(drop=True)\n",
    "aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment_negative</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2023</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.821764</td>\n",
       "      <td>1 January 2023 Euro banknotes and coins start ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-02-2022</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.764884</td>\n",
       "      <td>Banks had a generally benign view of firms’ an...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-02-2022</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.884606</td>\n",
       "      <td>A total of 152 banks were surveyed in this rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-02-2022</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.749230</td>\n",
       "      <td>1 February 2022 Credit standards tightened sli...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-06-2021</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.804409</td>\n",
       "      <td>1 June 2021 SME turnover and profits continued...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>31-05-2023</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.829122</td>\n",
       "      <td>31 May 2023 Tighter financial conditions test ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>31-08-1999</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.875617</td>\n",
       "      <td>The European Central Bank (ECB) is today relea...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>31-10-2022</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.740483</td>\n",
       "      <td>Turning to non-centrally cleared over-the coun...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>31-10-2022</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.943439</td>\n",
       "      <td>31 October 2022 Tighter credit terms and condi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>31-12-1998</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.928008</td>\n",
       "      <td>In accordance with Article 109l (4) of the Tre...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date sentiment  sentiment_score  \\\n",
       "0    01-01-2023   neutral         0.821764   \n",
       "1    01-02-2022  negative         0.764884   \n",
       "2    01-02-2022   neutral         0.884606   \n",
       "3    01-02-2022  positive         0.749230   \n",
       "4    01-06-2021  negative         0.804409   \n",
       "..          ...       ...              ...   \n",
       "415  31-05-2023  negative         0.829122   \n",
       "416  31-08-1999   neutral         0.875617   \n",
       "417  31-10-2022   neutral         0.740483   \n",
       "418  31-10-2022  negative         0.943439   \n",
       "419  31-12-1998   neutral         0.928008   \n",
       "\n",
       "                                               content  sentiment_negative  \\\n",
       "0    1 January 2023 Euro banknotes and coins start ...                   0   \n",
       "1    Banks had a generally benign view of firms’ an...                   1   \n",
       "2    A total of 152 banks were surveyed in this rou...                   0   \n",
       "3    1 February 2022 Credit standards tightened sli...                   0   \n",
       "4    1 June 2021 SME turnover and profits continued...                   1   \n",
       "..                                                 ...                 ...   \n",
       "415  31 May 2023 Tighter financial conditions test ...                   1   \n",
       "416  The European Central Bank (ECB) is today relea...                   0   \n",
       "417  Turning to non-centrally cleared over-the coun...                   0   \n",
       "418  31 October 2022 Tighter credit terms and condi...                   1   \n",
       "419  In accordance with Article 109l (4) of the Tre...                   0   \n",
       "\n",
       "     sentiment_neutral  sentiment_positive  \n",
       "0                    1                   0  \n",
       "1                    0                   0  \n",
       "2                    1                   0  \n",
       "3                    0                   1  \n",
       "4                    0                   0  \n",
       "..                 ...                 ...  \n",
       "415                  0                   0  \n",
       "416                  1                   0  \n",
       "417                  1                   0  \n",
       "418                  0                   0  \n",
       "419                  1                   0  \n",
       "\n",
       "[420 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variables for the 'sentiment' column\n",
    "sentiment_dummies = pd.get_dummies(aggregated_df['sentiment'], prefix='sentiment')\n",
    "\n",
    "# Convert True/False to 1/0\n",
    "sentiment_dummies = sentiment_dummies.astype(int)\n",
    "\n",
    "# Concatenate the dummies with the original DataFrame\n",
    "aggregated_df = pd.concat([aggregated_df, sentiment_dummies], axis=1)\n",
    "\n",
    "aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "neutral     660\n",
       "negative    210\n",
       "positive    143\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "press_releases_long['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# NO NEED TO RUN FOR NOW, IT\\'S BEEN SAVED AND WILL BE IMPORTED IN THE NEXT STEP\\n\\nsubset = press_releases\\nsubset[[\\'positive\\', \\'negative\\']] = subset[\\'content\\'].apply(lambda x: pd.Series(calculate_sentiment_finbert(x)))\\n\\n# Optional: Calculate the neutral sentiment as the remaining probability\\nsubset[\\'neutral\\'] = 1 - subset[\\'positive\\'] - subset[\\'negative\\']\\n\\n# current time and date\\ncurrent_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\\n\\n# Define the filename with the current date and time\\nfilename = f\"src/output/finbert_sentiment_press_releases_{current_datetime}.csv\"\\n\\n# Save the DataFrame to the specified filename\\nsubset.to_csv(filename, index=False)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# NO NEED TO RUN FOR NOW, IT'S BEEN SAVED AND WILL BE IMPORTED IN THE NEXT STEP\n",
    "\n",
    "subset = press_releases\n",
    "subset[['positive', 'negative']] = subset['content'].apply(lambda x: pd.Series(calculate_sentiment_finbert(x)))\n",
    "\n",
    "# Optional: Calculate the neutral sentiment as the remaining probability\n",
    "subset['neutral'] = 1 - subset['positive'] - subset['negative']\n",
    "\n",
    "# current time and date\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Define the filename with the current date and time\n",
    "filename = f\"src/output/finbert_sentiment_press_releases_{current_datetime}.csv\"\n",
    "\n",
    "# Save the DataFrame to the specified filename\n",
    "subset.to_csv(filename, index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment_negative</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.821764</td>\n",
       "      <td>1 January 2023 Euro banknotes and coins start ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.764884</td>\n",
       "      <td>Banks had a generally benign view of firms’ an...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.884606</td>\n",
       "      <td>A total of 152 banks were surveyed in this rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.749230</td>\n",
       "      <td>1 February 2022 Credit standards tightened sli...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.804409</td>\n",
       "      <td>1 June 2021 SME turnover and profits continued...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.829122</td>\n",
       "      <td>31 May 2023 Tighter financial conditions test ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1999-08-31</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.875617</td>\n",
       "      <td>The European Central Bank (ECB) is today relea...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.740483</td>\n",
       "      <td>Turning to non-centrally cleared over-the coun...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.943439</td>\n",
       "      <td>31 October 2022 Tighter credit terms and condi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1998-12-31</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.928008</td>\n",
       "      <td>In accordance with Article 109l (4) of the Tre...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1998-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date sentiment  sentiment_score  \\\n",
       "0   2023-01-01   neutral         0.821764   \n",
       "1   2022-02-01  negative         0.764884   \n",
       "2   2022-02-01   neutral         0.884606   \n",
       "3   2022-02-01  positive         0.749230   \n",
       "4   2021-06-01  negative         0.804409   \n",
       "..         ...       ...              ...   \n",
       "415 2023-05-31  negative         0.829122   \n",
       "416 1999-08-31   neutral         0.875617   \n",
       "417 2022-10-31   neutral         0.740483   \n",
       "418 2022-10-31  negative         0.943439   \n",
       "419 1998-12-31   neutral         0.928008   \n",
       "\n",
       "                                               content  sentiment_negative  \\\n",
       "0    1 January 2023 Euro banknotes and coins start ...                   0   \n",
       "1    Banks had a generally benign view of firms’ an...                   1   \n",
       "2    A total of 152 banks were surveyed in this rou...                   0   \n",
       "3    1 February 2022 Credit standards tightened sli...                   0   \n",
       "4    1 June 2021 SME turnover and profits continued...                   1   \n",
       "..                                                 ...                 ...   \n",
       "415  31 May 2023 Tighter financial conditions test ...                   1   \n",
       "416  The European Central Bank (ECB) is today relea...                   0   \n",
       "417  Turning to non-centrally cleared over-the coun...                   0   \n",
       "418  31 October 2022 Tighter credit terms and condi...                   1   \n",
       "419  In accordance with Article 109l (4) of the Tre...                   0   \n",
       "\n",
       "     sentiment_neutral  sentiment_positive       Date  \n",
       "0                    1                   0 2023-01-01  \n",
       "1                    0                   0 2022-02-01  \n",
       "2                    1                   0 2022-02-01  \n",
       "3                    0                   1 2022-02-01  \n",
       "4                    0                   0 2021-06-01  \n",
       "..                 ...                 ...        ...  \n",
       "415                  0                   0 2023-05-31  \n",
       "416                  1                   0 1999-08-31  \n",
       "417                  1                   0 2022-10-31  \n",
       "418                  0                   0 2022-10-31  \n",
       "419                  1                   0 1998-12-31  \n",
       "\n",
       "[420 rows x 8 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the saved CSV file into a DataFrame\n",
    "\n",
    "# change the data format to YYYY-MM-DD\n",
    "aggregated_df['Date'] = pd.to_datetime(aggregated_df['date'], format='%d-%m-%Y')\n",
    "aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock market data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Indexvalue</th>\n",
       "      <th>Date_merge</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>delta_daily</th>\n",
       "      <th>delta_3d</th>\n",
       "      <th>delta_5d</th>\n",
       "      <th>delta_30d</th>\n",
       "      <th>3d_pp_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-01-04</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>18.2033</td>\n",
       "      <td>04-01-1999</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-01-05</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>29.6912</td>\n",
       "      <td>05-01-1999</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>January</td>\n",
       "      <td>11.4879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-01-06</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>25.1670</td>\n",
       "      <td>06-01-1999</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "      <td>-4.5242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-01-07</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>32.5205</td>\n",
       "      <td>07-01-1999</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>January</td>\n",
       "      <td>7.3535</td>\n",
       "      <td>14.3172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-01-08</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>33.2296</td>\n",
       "      <td>08-01-1999</td>\n",
       "      <td>Friday</td>\n",
       "      <td>January</td>\n",
       "      <td>0.7091</td>\n",
       "      <td>3.5384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6268</th>\n",
       "      <td>2023-08-15</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>18.8579</td>\n",
       "      <td>15-08-2023</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>0.7815</td>\n",
       "      <td>-0.6814</td>\n",
       "      <td>4.7564</td>\n",
       "      <td>0.043233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>2023-08-16</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>18.5510</td>\n",
       "      <td>16-08-2023</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>August</td>\n",
       "      <td>-0.3069</td>\n",
       "      <td>0.1764</td>\n",
       "      <td>-0.4286</td>\n",
       "      <td>3.2565</td>\n",
       "      <td>0.009600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6270</th>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>20.3539</td>\n",
       "      <td>17-08-2023</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>August</td>\n",
       "      <td>1.8029</td>\n",
       "      <td>2.3010</td>\n",
       "      <td>2.2775</td>\n",
       "      <td>1.1262</td>\n",
       "      <td>0.127459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6271</th>\n",
       "      <td>2023-08-18</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>20.2456</td>\n",
       "      <td>18-08-2023</td>\n",
       "      <td>Friday</td>\n",
       "      <td>August</td>\n",
       "      <td>-0.1083</td>\n",
       "      <td>1.3877</td>\n",
       "      <td>1.8710</td>\n",
       "      <td>2.7082</td>\n",
       "      <td>0.073587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6272</th>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>19.8367</td>\n",
       "      <td>21-08-2023</td>\n",
       "      <td>Monday</td>\n",
       "      <td>August</td>\n",
       "      <td>-0.4089</td>\n",
       "      <td>1.2857</td>\n",
       "      <td>1.7838</td>\n",
       "      <td>2.3326</td>\n",
       "      <td>0.069306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6273 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Symbol  Indexvalue  Date_merge day_of_week    month  \\\n",
       "0    1999-01-04   V2TX     18.2033  04-01-1999      Monday  January   \n",
       "1    1999-01-05   V2TX     29.6912  05-01-1999     Tuesday  January   \n",
       "2    1999-01-06   V2TX     25.1670  06-01-1999   Wednesday  January   \n",
       "3    1999-01-07   V2TX     32.5205  07-01-1999    Thursday  January   \n",
       "4    1999-01-08   V2TX     33.2296  08-01-1999      Friday  January   \n",
       "...         ...    ...         ...         ...         ...      ...   \n",
       "6268 2023-08-15   V2TX     18.8579  15-08-2023     Tuesday   August   \n",
       "6269 2023-08-16   V2TX     18.5510  16-08-2023   Wednesday   August   \n",
       "6270 2023-08-17   V2TX     20.3539  17-08-2023    Thursday   August   \n",
       "6271 2023-08-18   V2TX     20.2456  18-08-2023      Friday   August   \n",
       "6272 2023-08-21   V2TX     19.8367  21-08-2023      Monday   August   \n",
       "\n",
       "      delta_daily  delta_3d  delta_5d  delta_30d  3d_pp_change  \n",
       "0             NaN       NaN       NaN        NaN           NaN  \n",
       "1         11.4879       NaN       NaN        NaN           NaN  \n",
       "2         -4.5242       NaN       NaN        NaN           NaN  \n",
       "3          7.3535   14.3172       NaN        NaN      0.786517  \n",
       "4          0.7091    3.5384       NaN        NaN      0.119173  \n",
       "...           ...       ...       ...        ...           ...  \n",
       "6268       0.8050    0.7815   -0.6814     4.7564      0.043233  \n",
       "6269      -0.3069    0.1764   -0.4286     3.2565      0.009600  \n",
       "6270       1.8029    2.3010    2.2775     1.1262      0.127459  \n",
       "6271      -0.1083    1.3877    1.8710     2.7082      0.073587  \n",
       "6272      -0.4089    1.2857    1.7838     2.3326      0.069306  \n",
       "\n",
       "[6273 rows x 11 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to your data file\n",
    "data_path = \"src/data/stoxx.txt\"\n",
    "\n",
    "# Read the data file into a DataFrame\n",
    "vstoxx_df = pd.read_csv(data_path, delimiter=\";\", parse_dates=[\"Date\"], dayfirst=True)\n",
    "\n",
    "# Change the date format to DD-MM-YYYY\n",
    "vstoxx_df[\"Date_merge\"] = vstoxx_df[\"Date\"].dt.strftime(\"%d-%m-%Y\")\n",
    "\n",
    "# generate day of the week column\n",
    "vstoxx_df['day_of_week'] = pd.to_datetime(vstoxx_df['Date']).dt.day_name()\n",
    "\n",
    "# generate month column\n",
    "vstoxx_df['month'] = pd.to_datetime(vstoxx_df['Date']).dt.month_name()\n",
    "\n",
    "# calculate the daily change in the index\n",
    "vstoxx_df['delta_daily'] = vstoxx_df['Indexvalue'].diff()\n",
    "vstoxx_df['delta_3d'] = vstoxx_df['Indexvalue'].diff(3)\n",
    "vstoxx_df['delta_5d'] = vstoxx_df['Indexvalue'].diff(5)\n",
    "vstoxx_df['delta_30d'] = vstoxx_df['Indexvalue'].diff(30)\n",
    "vstoxx_df['3d_pp_change'] = vstoxx_df['Indexvalue'].pct_change(3)\n",
    "\n",
    "# Display the DataFrame\n",
    "vstoxx_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment_negative</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Indexvalue</th>\n",
       "      <th>Date_merge</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>delta_daily</th>\n",
       "      <th>delta_3d</th>\n",
       "      <th>delta_5d</th>\n",
       "      <th>delta_30d</th>\n",
       "      <th>3d_pp_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.764884</td>\n",
       "      <td>Banks had a generally benign view of firms’ an...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>24.0892</td>\n",
       "      <td>01-02-2022</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>February</td>\n",
       "      <td>-2.9192</td>\n",
       "      <td>-3.9388</td>\n",
       "      <td>-7.3638</td>\n",
       "      <td>2.1050</td>\n",
       "      <td>-0.140531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.884606</td>\n",
       "      <td>A total of 152 banks were surveyed in this rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>24.0892</td>\n",
       "      <td>01-02-2022</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>February</td>\n",
       "      <td>-2.9192</td>\n",
       "      <td>-3.9388</td>\n",
       "      <td>-7.3638</td>\n",
       "      <td>2.1050</td>\n",
       "      <td>-0.140531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.749230</td>\n",
       "      <td>1 February 2022 Credit standards tightened sli...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>24.0892</td>\n",
       "      <td>01-02-2022</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>February</td>\n",
       "      <td>-2.9192</td>\n",
       "      <td>-3.9388</td>\n",
       "      <td>-7.3638</td>\n",
       "      <td>2.1050</td>\n",
       "      <td>-0.140531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.804409</td>\n",
       "      <td>1 June 2021 SME turnover and profits continued...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>18.7726</td>\n",
       "      <td>01-06-2021</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>June</td>\n",
       "      <td>-0.3255</td>\n",
       "      <td>0.9499</td>\n",
       "      <td>-0.3090</td>\n",
       "      <td>-2.3071</td>\n",
       "      <td>0.053297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.914993</td>\n",
       "      <td>SMEs reported that they expected to see an eco...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>18.7726</td>\n",
       "      <td>01-06-2021</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>June</td>\n",
       "      <td>-0.3255</td>\n",
       "      <td>0.9499</td>\n",
       "      <td>-0.3090</td>\n",
       "      <td>-2.3071</td>\n",
       "      <td>0.053297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.812764</td>\n",
       "      <td>Furthermore, there are already signs of deteri...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>19.9817</td>\n",
       "      <td>31-05-2023</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>May</td>\n",
       "      <td>2.0241</td>\n",
       "      <td>2.3846</td>\n",
       "      <td>-0.9483</td>\n",
       "      <td>3.0865</td>\n",
       "      <td>0.135511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.829122</td>\n",
       "      <td>31 May 2023 Tighter financial conditions test ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>19.9817</td>\n",
       "      <td>31-05-2023</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>May</td>\n",
       "      <td>2.0241</td>\n",
       "      <td>2.3846</td>\n",
       "      <td>-0.9483</td>\n",
       "      <td>3.0865</td>\n",
       "      <td>0.135511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>1999-08-31</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.875617</td>\n",
       "      <td>The European Central Bank (ECB) is today relea...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1999-08-31</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>24.9551</td>\n",
       "      <td>31-08-1999</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>1.7211</td>\n",
       "      <td>2.1743</td>\n",
       "      <td>-0.0327</td>\n",
       "      <td>3.1224</td>\n",
       "      <td>0.095444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.740483</td>\n",
       "      <td>Turning to non-centrally cleared over-the coun...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>24.8305</td>\n",
       "      <td>31-10-2022</td>\n",
       "      <td>Monday</td>\n",
       "      <td>October</td>\n",
       "      <td>-0.0599</td>\n",
       "      <td>-2.1174</td>\n",
       "      <td>-3.8489</td>\n",
       "      <td>-1.3562</td>\n",
       "      <td>-0.078574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.943439</td>\n",
       "      <td>31 October 2022 Tighter credit terms and condi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>24.8305</td>\n",
       "      <td>31-10-2022</td>\n",
       "      <td>Monday</td>\n",
       "      <td>October</td>\n",
       "      <td>-0.0599</td>\n",
       "      <td>-2.1174</td>\n",
       "      <td>-3.8489</td>\n",
       "      <td>-1.3562</td>\n",
       "      <td>-0.078574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date sentiment  sentiment_score  \\\n",
       "0   2022-02-01  negative         0.764884   \n",
       "1   2022-02-01   neutral         0.884606   \n",
       "2   2022-02-01  positive         0.749230   \n",
       "3   2021-06-01  negative         0.804409   \n",
       "4   2021-06-01   neutral         0.914993   \n",
       "..         ...       ...              ...   \n",
       "374 2023-05-31   neutral         0.812764   \n",
       "375 2023-05-31  negative         0.829122   \n",
       "376 1999-08-31   neutral         0.875617   \n",
       "377 2022-10-31   neutral         0.740483   \n",
       "378 2022-10-31  negative         0.943439   \n",
       "\n",
       "                                               content  sentiment_negative  \\\n",
       "0    Banks had a generally benign view of firms’ an...                   1   \n",
       "1    A total of 152 banks were surveyed in this rou...                   0   \n",
       "2    1 February 2022 Credit standards tightened sli...                   0   \n",
       "3    1 June 2021 SME turnover and profits continued...                   1   \n",
       "4    SMEs reported that they expected to see an eco...                   0   \n",
       "..                                                 ...                 ...   \n",
       "374  Furthermore, there are already signs of deteri...                   0   \n",
       "375  31 May 2023 Tighter financial conditions test ...                   1   \n",
       "376  The European Central Bank (ECB) is today relea...                   0   \n",
       "377  Turning to non-centrally cleared over-the coun...                   0   \n",
       "378  31 October 2022 Tighter credit terms and condi...                   1   \n",
       "\n",
       "     sentiment_neutral  sentiment_positive       Date Symbol  Indexvalue  \\\n",
       "0                    0                   0 2022-02-01   V2TX     24.0892   \n",
       "1                    1                   0 2022-02-01   V2TX     24.0892   \n",
       "2                    0                   1 2022-02-01   V2TX     24.0892   \n",
       "3                    0                   0 2021-06-01   V2TX     18.7726   \n",
       "4                    1                   0 2021-06-01   V2TX     18.7726   \n",
       "..                 ...                 ...        ...    ...         ...   \n",
       "374                  1                   0 2023-05-31   V2TX     19.9817   \n",
       "375                  0                   0 2023-05-31   V2TX     19.9817   \n",
       "376                  1                   0 1999-08-31   V2TX     24.9551   \n",
       "377                  1                   0 2022-10-31   V2TX     24.8305   \n",
       "378                  0                   0 2022-10-31   V2TX     24.8305   \n",
       "\n",
       "     Date_merge day_of_week     month  delta_daily  delta_3d  delta_5d  \\\n",
       "0    01-02-2022     Tuesday  February      -2.9192   -3.9388   -7.3638   \n",
       "1    01-02-2022     Tuesday  February      -2.9192   -3.9388   -7.3638   \n",
       "2    01-02-2022     Tuesday  February      -2.9192   -3.9388   -7.3638   \n",
       "3    01-06-2021     Tuesday      June      -0.3255    0.9499   -0.3090   \n",
       "4    01-06-2021     Tuesday      June      -0.3255    0.9499   -0.3090   \n",
       "..          ...         ...       ...          ...       ...       ...   \n",
       "374  31-05-2023   Wednesday       May       2.0241    2.3846   -0.9483   \n",
       "375  31-05-2023   Wednesday       May       2.0241    2.3846   -0.9483   \n",
       "376  31-08-1999     Tuesday    August       1.7211    2.1743   -0.0327   \n",
       "377  31-10-2022      Monday   October      -0.0599   -2.1174   -3.8489   \n",
       "378  31-10-2022      Monday   October      -0.0599   -2.1174   -3.8489   \n",
       "\n",
       "     delta_30d  3d_pp_change  \n",
       "0       2.1050     -0.140531  \n",
       "1       2.1050     -0.140531  \n",
       "2       2.1050     -0.140531  \n",
       "3      -2.3071      0.053297  \n",
       "4      -2.3071      0.053297  \n",
       "..         ...           ...  \n",
       "374     3.0865      0.135511  \n",
       "375     3.0865      0.135511  \n",
       "376     3.1224      0.095444  \n",
       "377    -1.3562     -0.078574  \n",
       "378    -1.3562     -0.078574  \n",
       "\n",
       "[379 rows x 18 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Merging the dataframes based on the intersection of their 'Date' columns\n",
    "merged_df = pd.merge(aggregated_df, vstoxx_df, on='Date', how='inner')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               delta_3d   R-squared:                       0.120\n",
      "Model:                            OLS   Adj. R-squared:                  0.104\n",
      "Method:                 Least Squares   F-statistic:                     7.203\n",
      "Date:                Sat, 02 Sep 2023   Prob (F-statistic):           4.33e-08\n",
      "Time:                        12:22:56   Log-Likelihood:                -894.86\n",
      "No. Observations:                 376   AIC:                             1806.\n",
      "Df Residuals:                     368   BIC:                             1837.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "Intercept                   -3.1495      0.667     -4.723      0.000      -4.461      -1.838\n",
      "day_of_week[T.Monday]        2.4398      0.586      4.167      0.000       1.288       3.591\n",
      "day_of_week[T.Thursday]      0.4412      0.440      1.004      0.316      -0.423       1.306\n",
      "day_of_week[T.Tuesday]       1.3899      0.467      2.977      0.003       0.472       2.308\n",
      "day_of_week[T.Wednesday]     1.8040      0.471      3.831      0.000       0.878       2.730\n",
      "sentiment_negative           0.1078      0.343      0.314      0.753      -0.566       0.782\n",
      "sentiment_positive           0.2257      0.341      0.661      0.509      -0.446       0.897\n",
      "Indexvalue                   0.0842      0.025      3.423      0.001       0.036       0.133\n",
      "==============================================================================\n",
      "Omnibus:                       50.733   Durbin-Watson:                   1.254\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              147.068\n",
      "Skew:                           0.613   Prob(JB):                     1.16e-32\n",
      "Kurtosis:                       5.808   Cond. No.                         154.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Define the regression formula\n",
    "\n",
    "\n",
    "formula = \"delta_3d ~ sentiment_negative + sentiment_positive + Indexvalue + day_of_week\"\n",
    "\n",
    "# Define the model\n",
    "model = smf.ols(formula=formula, data=merged_df)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the results\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>delta_daily</th>\n",
       "      <th>sentiment_negative</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-02-2022</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>February</td>\n",
       "      <td>-1.523805</td>\n",
       "      <td>1.598837</td>\n",
       "      <td>-0.536026</td>\n",
       "      <td>-1.076656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-02-2022</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>February</td>\n",
       "      <td>-1.523805</td>\n",
       "      <td>-0.537542</td>\n",
       "      <td>-0.536026</td>\n",
       "      <td>0.951817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-02-2022</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>February</td>\n",
       "      <td>-1.523805</td>\n",
       "      <td>-0.537542</td>\n",
       "      <td>1.852348</td>\n",
       "      <td>-1.076656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-06-2021</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>June</td>\n",
       "      <td>-0.138697</td>\n",
       "      <td>1.709234</td>\n",
       "      <td>-0.536026</td>\n",
       "      <td>-1.076656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-06-2021</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>June</td>\n",
       "      <td>-0.138697</td>\n",
       "      <td>-0.537542</td>\n",
       "      <td>-0.536026</td>\n",
       "      <td>1.021499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>31-05-2023</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>May</td>\n",
       "      <td>1.116054</td>\n",
       "      <td>-0.537542</td>\n",
       "      <td>-0.536026</td>\n",
       "      <td>0.787079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>31-05-2023</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>May</td>\n",
       "      <td>1.116054</td>\n",
       "      <td>1.778259</td>\n",
       "      <td>-0.536026</td>\n",
       "      <td>-1.076656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>31-08-1999</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>0.954244</td>\n",
       "      <td>-0.537542</td>\n",
       "      <td>-0.536026</td>\n",
       "      <td>0.931206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>31-10-2022</td>\n",
       "      <td>Monday</td>\n",
       "      <td>October</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>-0.537542</td>\n",
       "      <td>-0.536026</td>\n",
       "      <td>0.621333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>31-10-2022</td>\n",
       "      <td>Monday</td>\n",
       "      <td>October</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>2.097555</td>\n",
       "      <td>-0.536026</td>\n",
       "      <td>-1.076656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date day_of_week     month  delta_daily  sentiment_negative  \\\n",
       "0    01-02-2022     Tuesday  February    -1.523805            1.598837   \n",
       "1    01-02-2022     Tuesday  February    -1.523805           -0.537542   \n",
       "2    01-02-2022     Tuesday  February    -1.523805           -0.537542   \n",
       "3    01-06-2021     Tuesday      June    -0.138697            1.709234   \n",
       "4    01-06-2021     Tuesday      June    -0.138697           -0.537542   \n",
       "..          ...         ...       ...          ...                 ...   \n",
       "373  31-05-2023   Wednesday       May     1.116054           -0.537542   \n",
       "374  31-05-2023   Wednesday       May     1.116054            1.778259   \n",
       "375  31-08-1999     Tuesday    August     0.954244           -0.537542   \n",
       "376  31-10-2022      Monday   October     0.003141           -0.537542   \n",
       "377  31-10-2022      Monday   October     0.003141            2.097555   \n",
       "\n",
       "     sentiment_positive  sentiment_neutral  \n",
       "0             -0.536026          -1.076656  \n",
       "1             -0.536026           0.951817  \n",
       "2              1.852348          -1.076656  \n",
       "3             -0.536026          -1.076656  \n",
       "4             -0.536026           1.021499  \n",
       "..                  ...                ...  \n",
       "373           -0.536026           0.787079  \n",
       "374           -0.536026          -1.076656  \n",
       "375           -0.536026           0.931206  \n",
       "376           -0.536026           0.621333  \n",
       "377           -0.536026          -1.076656  \n",
       "\n",
       "[378 rows x 7 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a new DataFrame 'standardized'\n",
    "standardized = pd.DataFrame()\n",
    "\n",
    "# Copy necessary columns from merged_df\n",
    "standardized['date'] = merged_df['Date_merge']\n",
    "standardized['day_of_week'] = merged_df['day_of_week']\n",
    "standardized['month'] = merged_df['month']\n",
    "\n",
    "# Standardize the 'delta_daily' column\n",
    "standardized['delta_daily'] = StandardScaler().fit_transform(merged_df['delta_daily'].values.reshape(-1, 1))\n",
    "\n",
    "# Calculate 'sentiment_negative' column based on 'sentiment_score'\n",
    "standardized['sentiment_negative'] = merged_df['sentiment_negative'] * merged_df['sentiment_score']\n",
    "standardized['sentiment_positive'] = merged_df['sentiment_positive'] * merged_df['sentiment_score']\n",
    "standardized['sentiment_neutral'] = merged_df['sentiment_neutral'] * merged_df['sentiment_score']\n",
    "\n",
    "# Standardize the 'sentiment_negative' column\n",
    "standardized['sentiment_negative'] = StandardScaler().fit_transform(standardized['sentiment_negative'].values.reshape(-1, 1))\n",
    "standardized['sentiment_positive'] = StandardScaler().fit_transform(standardized['sentiment_positive'].values.reshape(-1, 1))\n",
    "standardized['sentiment_neutral'] = StandardScaler().fit_transform(standardized['sentiment_neutral'].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# Filter out rows with NaN values in the 'sentiment_negative' column\n",
    "standardized = standardized.dropna(subset=['sentiment_negative' , \"delta_daily\"])\n",
    "\n",
    "# reset index\n",
    "standardized = standardized.reset_index(drop=True)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "standardized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            delta_daily   R-squared:                       0.043\n",
      "Model:                            OLS   Adj. R-squared:                  0.030\n",
      "Method:                 Least Squares   F-statistic:                     3.335\n",
      "Date:                Sat, 02 Sep 2023   Prob (F-statistic):            0.00584\n",
      "Time:                        12:11:56   Log-Likelihood:                -528.07\n",
      "No. Observations:                 378   AIC:                             1068.\n",
      "Df Residuals:                     372   BIC:                             1092.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "Intercept                   -0.1706      0.137     -1.245      0.214      -0.440       0.099\n",
      "day_of_week[T.Monday]        0.6307      0.215      2.936      0.004       0.208       1.053\n",
      "day_of_week[T.Thursday]     -0.0313      0.164     -0.191      0.848      -0.354       0.291\n",
      "day_of_week[T.Tuesday]       0.2916      0.173      1.688      0.092      -0.048       0.631\n",
      "day_of_week[T.Wednesday]     0.2458      0.176      1.400      0.162      -0.099       0.591\n",
      "sentiment_negative           0.0468      0.051      0.919      0.359      -0.053       0.147\n",
      "==============================================================================\n",
      "Omnibus:                      133.117   Durbin-Watson:                   1.147\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1091.213\n",
      "Skew:                           1.246   Prob(JB):                    1.11e-237\n",
      "Kurtosis:                      10.942   Cond. No.                         7.12\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# ols regression model \n",
    "\n",
    "# delta_daily against sentiment_negative, sentiment_positive, sentiment_neutral and day_of_week\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Define the regression formula\n",
    "\n",
    "# formula = \"delta_daily ~ sentiment_negative + sentiment_positive + sentiment_neutral + day_of_week + month\"\n",
    "\n",
    "formula = \"delta_daily ~ sentiment_negative + day_of_week\"\n",
    "\n",
    "# Define the model\n",
    "model = smf.ols(formula=formula, data=standardized)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the results\n",
    "print(results.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9079/2661862225.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bond_data['b_delta_daily'] = bond_data['bond_price'].diff()\n",
      "/tmp/ipykernel_9079/2661862225.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bond_data['b_delta_3d'] = bond_data['bond_price'].diff(3)\n",
      "/tmp/ipykernel_9079/2661862225.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bond_data['b_delta_5d'] = bond_data['bond_price'].diff(5)\n",
      "/tmp/ipykernel_9079/2661862225.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bond_data['b_delta_30d'] = bond_data['bond_price'].diff(30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>bond_price</th>\n",
       "      <th>b_delta_daily</th>\n",
       "      <th>b_delta_3d</th>\n",
       "      <th>b_delta_5d</th>\n",
       "      <th>b_delta_30d</th>\n",
       "      <th>b_3d_pp_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-10-23</td>\n",
       "      <td>20.524279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-10-24</td>\n",
       "      <td>20.475510</td>\n",
       "      <td>-0.048769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-10-27</td>\n",
       "      <td>20.343826</td>\n",
       "      <td>-0.131683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-10-28</td>\n",
       "      <td>20.735619</td>\n",
       "      <td>0.391792</td>\n",
       "      <td>0.211340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-10-29</td>\n",
       "      <td>20.865671</td>\n",
       "      <td>0.130053</td>\n",
       "      <td>0.390162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>2023-07-25</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>0.130001</td>\n",
       "      <td>-0.049999</td>\n",
       "      <td>-0.309999</td>\n",
       "      <td>1.268011</td>\n",
       "      <td>-0.001658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>2023-07-26</td>\n",
       "      <td>30.080000</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>-0.240000</td>\n",
       "      <td>0.866453</td>\n",
       "      <td>-0.002322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>2023-07-27</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>0.030001</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>0.590784</td>\n",
       "      <td>0.001001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>30.490000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.389999</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.982948</td>\n",
       "      <td>0.012957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>30.410000</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.440001</td>\n",
       "      <td>0.462690</td>\n",
       "      <td>0.010971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2206 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  bond_price  b_delta_daily  b_delta_3d  b_delta_5d  \\\n",
       "0    2014-10-23   20.524279            NaN         NaN         NaN   \n",
       "1    2014-10-24   20.475510      -0.048769         NaN         NaN   \n",
       "2    2014-10-27   20.343826      -0.131683         NaN         NaN   \n",
       "3    2014-10-28   20.735619       0.391792    0.211340         NaN   \n",
       "4    2014-10-29   20.865671       0.130053    0.390162         NaN   \n",
       "...         ...         ...            ...         ...         ...   \n",
       "2201 2023-07-25   30.100000       0.130001   -0.049999   -0.309999   \n",
       "2202 2023-07-26   30.080000      -0.020000   -0.070000   -0.240000   \n",
       "2203 2023-07-27   30.000000      -0.080000    0.030001   -0.150000   \n",
       "2204 2023-07-28   30.490000       0.490000    0.389999    0.340000   \n",
       "2205 2023-07-31   30.410000      -0.080000    0.330000    0.440001   \n",
       "\n",
       "      b_delta_30d  b_3d_pp_change  \n",
       "0             NaN             NaN  \n",
       "1             NaN             NaN  \n",
       "2             NaN             NaN  \n",
       "3             NaN        0.010297  \n",
       "4             NaN        0.019055  \n",
       "...           ...             ...  \n",
       "2201     1.268011       -0.001658  \n",
       "2202     0.866453       -0.002322  \n",
       "2203     0.590784        0.001001  \n",
       "2204     0.982948        0.012957  \n",
       "2205     0.462690        0.010971  \n",
       "\n",
       "[2206 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bond prices\n",
    "\n",
    "# Define the ticker symbol for the Eurozone bond you're interested in\n",
    "bond_ticker = [\"DAX\"]\n",
    "\n",
    "# Define the start and end dates for the data you want to fetch\n",
    "start_date = \"2000-01-01\"\n",
    "end_date = \"2023-08-01\"\n",
    "\n",
    "# Fetch the bond price data using yfinance\n",
    "bond_data = yf.download(bond_ticker, start=start_date, end=end_date)\n",
    "\n",
    "# remove the 1st row for Date, and keep it in 0th row\n",
    "bond_data.reset_index(inplace=True)\n",
    "\n",
    "# keep only date and adjusted close columns\n",
    "bond_data = bond_data[['Date','Adj Close']]\n",
    "bond_data.columns = ['Date', 'bond_price']\n",
    "\n",
    "# generate more variables\n",
    "bond_data['b_delta_daily'] = bond_data['bond_price'].diff()\n",
    "bond_data['b_delta_3d'] = bond_data['bond_price'].diff(3)\n",
    "bond_data['b_delta_5d'] = bond_data['bond_price'].diff(5)\n",
    "bond_data['b_delta_30d'] = bond_data['bond_price'].diff(30)\n",
    "bond_data['b_3d_pp_change'] = bond_data['bond_price'].pct_change(3)\n",
    "\n",
    "# Display the downloaded data\n",
    "bond_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Indexvalue</th>\n",
       "      <th>Date_merge</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>delta_daily</th>\n",
       "      <th>delta_3d</th>\n",
       "      <th>delta_5d</th>\n",
       "      <th>delta_30d</th>\n",
       "      <th>...</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>bond_price</th>\n",
       "      <th>b_delta_daily</th>\n",
       "      <th>b_delta_3d</th>\n",
       "      <th>b_delta_5d</th>\n",
       "      <th>b_delta_30d</th>\n",
       "      <th>b_3d_pp_change</th>\n",
       "      <th>b_delta_3d_pct_lag</th>\n",
       "      <th>delta_3d_pct_lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-01-04</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>18.2033</td>\n",
       "      <td>04-01-1999</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-01-05</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>29.6912</td>\n",
       "      <td>05-01-1999</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>January</td>\n",
       "      <td>11.4879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-01-05</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>29.6912</td>\n",
       "      <td>05-01-1999</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>January</td>\n",
       "      <td>11.4879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-01-06</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>25.1670</td>\n",
       "      <td>06-01-1999</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "      <td>-4.5242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-01-07</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>32.5205</td>\n",
       "      <td>07-01-1999</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>January</td>\n",
       "      <td>7.3535</td>\n",
       "      <td>14.3172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6508</th>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.150692</td>\n",
       "      <td>0.658386</td>\n",
       "      <td>1.090830</td>\n",
       "      <td>1.319551</td>\n",
       "      <td>2.166845</td>\n",
       "      <td>0.036289</td>\n",
       "      <td>-0.003697</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6509</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.720982</td>\n",
       "      <td>0.192863</td>\n",
       "      <td>0.041094</td>\n",
       "      <td>0.326971</td>\n",
       "      <td>-0.574852</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.007830</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6510</th>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.842300</td>\n",
       "      <td>-0.114010</td>\n",
       "      <td>0.057957</td>\n",
       "      <td>-0.437037</td>\n",
       "      <td>1.339621</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>-0.016633</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6511</th>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.802639</td>\n",
       "      <td>-0.097836</td>\n",
       "      <td>-0.088053</td>\n",
       "      <td>0.088051</td>\n",
       "      <td>1.653412</td>\n",
       "      <td>-0.003048</td>\n",
       "      <td>0.036289</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6512</th>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.663588</td>\n",
       "      <td>0.029350</td>\n",
       "      <td>0.430475</td>\n",
       "      <td>0.117401</td>\n",
       "      <td>3.120939</td>\n",
       "      <td>0.014726</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6513 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Symbol  Indexvalue  Date_merge day_of_week    month  \\\n",
       "0    1999-01-04   V2TX     18.2033  04-01-1999      Monday  January   \n",
       "1    1999-01-05   V2TX     29.6912  05-01-1999     Tuesday  January   \n",
       "2    1999-01-05   V2TX     29.6912  05-01-1999     Tuesday  January   \n",
       "3    1999-01-06   V2TX     25.1670  06-01-1999   Wednesday  January   \n",
       "4    1999-01-07   V2TX     32.5205  07-01-1999    Thursday  January   \n",
       "...         ...    ...         ...         ...         ...      ...   \n",
       "6508 2021-04-05    NaN         NaN         NaN         NaN      NaN   \n",
       "6509 2021-12-31    NaN         NaN         NaN         NaN      NaN   \n",
       "6510 2022-04-18    NaN         NaN         NaN         NaN      NaN   \n",
       "6511 2023-04-10    NaN         NaN         NaN         NaN      NaN   \n",
       "6512 2023-05-01    NaN         NaN         NaN         NaN      NaN   \n",
       "\n",
       "      delta_daily  delta_3d  delta_5d  delta_30d  ...  sentiment_neutral  \\\n",
       "0             NaN       NaN       NaN        NaN  ...                1.0   \n",
       "1         11.4879       NaN       NaN        NaN  ...                0.0   \n",
       "2         11.4879       NaN       NaN        NaN  ...                1.0   \n",
       "3         -4.5242       NaN       NaN        NaN  ...                NaN   \n",
       "4          7.3535   14.3172       NaN        NaN  ...                1.0   \n",
       "...           ...       ...       ...        ...  ...                ...   \n",
       "6508          NaN       NaN       NaN        NaN  ...                NaN   \n",
       "6509          NaN       NaN       NaN        NaN  ...                NaN   \n",
       "6510          NaN       NaN       NaN        NaN  ...                NaN   \n",
       "6511          NaN       NaN       NaN        NaN  ...                NaN   \n",
       "6512          NaN       NaN       NaN        NaN  ...                NaN   \n",
       "\n",
       "     sentiment_positive bond_price  b_delta_daily  b_delta_3d  b_delta_5d  \\\n",
       "0                   0.0        NaN            NaN         NaN         NaN   \n",
       "1                   0.0        NaN            NaN         NaN         NaN   \n",
       "2                   0.0        NaN            NaN         NaN         NaN   \n",
       "3                   NaN        NaN            NaN         NaN         NaN   \n",
       "4                   0.0        NaN            NaN         NaN         NaN   \n",
       "...                 ...        ...            ...         ...         ...   \n",
       "6508                NaN  31.150692       0.658386    1.090830    1.319551   \n",
       "6509                NaN  30.720982       0.192863    0.041094    0.326971   \n",
       "6510                NaN  25.842300      -0.114010    0.057957   -0.437037   \n",
       "6511                NaN  28.802639      -0.097836   -0.088053    0.088051   \n",
       "6512                NaN  29.663588       0.029350    0.430475    0.117401   \n",
       "\n",
       "      b_delta_30d  b_3d_pp_change  b_delta_3d_pct_lag  delta_3d_pct_lag  \n",
       "0             NaN             NaN                 NaN               NaN  \n",
       "1             NaN             NaN                 NaN               NaN  \n",
       "2             NaN             NaN                 NaN               NaN  \n",
       "3             NaN             NaN                 NaN               NaN  \n",
       "4             NaN             NaN                 NaN               NaN  \n",
       "...           ...             ...                 ...               ...  \n",
       "6508     2.166845        0.036289           -0.003697               NaN  \n",
       "6509    -0.574852        0.001339            0.007830               NaN  \n",
       "6510     1.339621        0.002248           -0.016633               NaN  \n",
       "6511     1.653412       -0.003048            0.036289               NaN  \n",
       "6512     3.120939        0.014726            0.001339               NaN  \n",
       "\n",
       "[6513 rows x 25 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge bond and merged_df\n",
    "merged_df = pd.merge(merged_df, bond_data, left_on='Date', right_on='Date', how='outer')\n",
    "# create 3 day lagged percentage change\n",
    "merged_df['b_delta_3d_pct_lag'] = merged_df['b_3d_pp_change'].shift(3)\n",
    "merged_df['delta_3d_pct_lag'] = merged_df['3d_pp_change'].shift(3)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Indexvalue</th>\n",
       "      <th>delta_daily</th>\n",
       "      <th>delta_3d</th>\n",
       "      <th>delta_5d</th>\n",
       "      <th>delta_30d</th>\n",
       "      <th>3d_pp_change</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_negative</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>bond_price</th>\n",
       "      <th>b_delta_daily</th>\n",
       "      <th>b_delta_3d</th>\n",
       "      <th>b_delta_5d</th>\n",
       "      <th>b_delta_30d</th>\n",
       "      <th>b_3d_pp_change</th>\n",
       "      <th>b_delta_3d_pct_lag</th>\n",
       "      <th>delta_3d_pct_lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6472</td>\n",
       "      <td>6442.000000</td>\n",
       "      <td>6441.000000</td>\n",
       "      <td>6438.000000</td>\n",
       "      <td>6436.000000</td>\n",
       "      <td>6407.000000</td>\n",
       "      <td>6438.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>2363.000000</td>\n",
       "      <td>2362.000000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>2358.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>2357.000000</td>\n",
       "      <td>6438.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2011-08-15 05:05:42.645240832</td>\n",
       "      <td>23.745494</td>\n",
       "      <td>-0.000812</td>\n",
       "      <td>-0.002198</td>\n",
       "      <td>-0.001188</td>\n",
       "      <td>-0.117159</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.834390</td>\n",
       "      <td>0.211905</td>\n",
       "      <td>0.573810</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>24.707562</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.015055</td>\n",
       "      <td>0.025226</td>\n",
       "      <td>0.137136</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.005630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1999-01-04 00:00:00</td>\n",
       "      <td>10.678300</td>\n",
       "      <td>-13.987300</td>\n",
       "      <td>-31.328600</td>\n",
       "      <td>-27.666400</td>\n",
       "      <td>-54.900100</td>\n",
       "      <td>-0.403941</td>\n",
       "      <td>0.394449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.713292</td>\n",
       "      <td>-2.268639</td>\n",
       "      <td>-3.506903</td>\n",
       "      <td>-4.961187</td>\n",
       "      <td>-9.587053</td>\n",
       "      <td>-0.175011</td>\n",
       "      <td>-0.175011</td>\n",
       "      <td>-0.403941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2005-05-02 18:00:00</td>\n",
       "      <td>17.352175</td>\n",
       "      <td>-0.796700</td>\n",
       "      <td>-1.357775</td>\n",
       "      <td>-1.724875</td>\n",
       "      <td>-3.564600</td>\n",
       "      <td>-0.061544</td>\n",
       "      <td>0.767635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.853713</td>\n",
       "      <td>-0.154525</td>\n",
       "      <td>-0.254741</td>\n",
       "      <td>-0.298640</td>\n",
       "      <td>-0.699909</td>\n",
       "      <td>-0.010454</td>\n",
       "      <td>-0.010565</td>\n",
       "      <td>-0.061544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2011-09-05 12:00:00</td>\n",
       "      <td>21.840200</td>\n",
       "      <td>-0.100400</td>\n",
       "      <td>-0.137300</td>\n",
       "      <td>-0.178650</td>\n",
       "      <td>-0.639700</td>\n",
       "      <td>-0.006937</td>\n",
       "      <td>0.866406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.553036</td>\n",
       "      <td>0.008644</td>\n",
       "      <td>0.029675</td>\n",
       "      <td>0.068186</td>\n",
       "      <td>0.235357</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>-0.006937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2017-12-28 06:00:00</td>\n",
       "      <td>27.316325</td>\n",
       "      <td>0.663400</td>\n",
       "      <td>1.188250</td>\n",
       "      <td>1.443900</td>\n",
       "      <td>2.523200</td>\n",
       "      <td>0.057071</td>\n",
       "      <td>0.926595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.141617</td>\n",
       "      <td>0.184257</td>\n",
       "      <td>0.329349</td>\n",
       "      <td>0.400460</td>\n",
       "      <td>1.089788</td>\n",
       "      <td>0.013057</td>\n",
       "      <td>0.013048</td>\n",
       "      <td>0.057071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023-08-21 00:00:00</td>\n",
       "      <td>87.512700</td>\n",
       "      <td>22.641500</td>\n",
       "      <td>31.859100</td>\n",
       "      <td>39.871200</td>\n",
       "      <td>71.191700</td>\n",
       "      <td>0.947828</td>\n",
       "      <td>0.972653</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.657291</td>\n",
       "      <td>1.835562</td>\n",
       "      <td>2.723280</td>\n",
       "      <td>3.080296</td>\n",
       "      <td>5.618279</td>\n",
       "      <td>0.167343</td>\n",
       "      <td>0.167343</td>\n",
       "      <td>0.947828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.302241</td>\n",
       "      <td>1.814967</td>\n",
       "      <td>2.984199</td>\n",
       "      <td>3.684632</td>\n",
       "      <td>7.285938</td>\n",
       "      <td>0.110118</td>\n",
       "      <td>0.115070</td>\n",
       "      <td>0.409145</td>\n",
       "      <td>0.495112</td>\n",
       "      <td>0.410815</td>\n",
       "      <td>3.636605</td>\n",
       "      <td>0.325765</td>\n",
       "      <td>0.550841</td>\n",
       "      <td>0.710288</td>\n",
       "      <td>1.672240</td>\n",
       "      <td>0.023749</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>0.110118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Date   Indexvalue  delta_daily     delta_3d  \\\n",
       "count                           6472  6442.000000  6441.000000  6438.000000   \n",
       "mean   2011-08-15 05:05:42.645240832    23.745494    -0.000812    -0.002198   \n",
       "min              1999-01-04 00:00:00    10.678300   -13.987300   -31.328600   \n",
       "25%              2005-05-02 18:00:00    17.352175    -0.796700    -1.357775   \n",
       "50%              2011-09-05 12:00:00    21.840200    -0.100400    -0.137300   \n",
       "75%              2017-12-28 06:00:00    27.316325     0.663400     1.188250   \n",
       "max              2023-08-21 00:00:00    87.512700    22.641500    31.859100   \n",
       "std                              NaN     9.302241     1.814967     2.984199   \n",
       "\n",
       "          delta_5d    delta_30d  3d_pp_change  sentiment_score  \\\n",
       "count  6436.000000  6407.000000   6438.000000       420.000000   \n",
       "mean     -0.001188    -0.117159      0.005630         0.834390   \n",
       "min     -27.666400   -54.900100     -0.403941         0.394449   \n",
       "25%      -1.724875    -3.564600     -0.061544         0.767635   \n",
       "50%      -0.178650    -0.639700     -0.006937         0.866406   \n",
       "75%       1.443900     2.523200      0.057071         0.926595   \n",
       "max      39.871200    71.191700      0.947828         0.972653   \n",
       "std       3.684632     7.285938      0.110118         0.115070   \n",
       "\n",
       "       sentiment_negative  sentiment_neutral  sentiment_positive   bond_price  \\\n",
       "count          420.000000         420.000000          420.000000  2363.000000   \n",
       "mean             0.211905           0.573810            0.214286    24.707562   \n",
       "min              0.000000           0.000000            0.000000    15.713292   \n",
       "25%              0.000000           0.000000            0.000000    21.853713   \n",
       "50%              0.000000           1.000000            0.000000    24.553036   \n",
       "75%              0.000000           1.000000            0.000000    27.141617   \n",
       "max              1.000000           1.000000            1.000000    32.657291   \n",
       "std              0.409145           0.495112            0.410815     3.636605   \n",
       "\n",
       "       b_delta_daily   b_delta_3d   b_delta_5d  b_delta_30d  b_3d_pp_change  \\\n",
       "count    2362.000000  2360.000000  2358.000000  2333.000000     2360.000000   \n",
       "mean        0.003771     0.015055     0.025226     0.137136        0.000881   \n",
       "min        -2.268639    -3.506903    -4.961187    -9.587053       -0.175011   \n",
       "25%        -0.154525    -0.254741    -0.298640    -0.699909       -0.010454   \n",
       "50%         0.008644     0.029675     0.068186     0.235357        0.001183   \n",
       "75%         0.184257     0.329349     0.400460     1.089788        0.013057   \n",
       "max         1.835562     2.723280     3.080296     5.618279        0.167343   \n",
       "std         0.325765     0.550841     0.710288     1.672240        0.023749   \n",
       "\n",
       "       b_delta_3d_pct_lag  delta_3d_pct_lag  \n",
       "count         2357.000000       6438.000000  \n",
       "mean             0.000876          0.005630  \n",
       "min             -0.175011         -0.403941  \n",
       "25%             -0.010565         -0.061544  \n",
       "50%              0.001176         -0.006937  \n",
       "75%              0.013048          0.057071  \n",
       "max              0.167343          0.947828  \n",
       "std              0.023762          0.110118  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Indexvalue</th>\n",
       "      <th>Date_merge</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>delta_daily</th>\n",
       "      <th>delta_3d</th>\n",
       "      <th>delta_5d</th>\n",
       "      <th>...</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>bond_price</th>\n",
       "      <th>b_delta_daily</th>\n",
       "      <th>b_delta_3d</th>\n",
       "      <th>b_delta_5d</th>\n",
       "      <th>b_delta_30d</th>\n",
       "      <th>b_3d_pp_change</th>\n",
       "      <th>b_delta_3d_pct_lag</th>\n",
       "      <th>delta_3d_pct_lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1999-01-04</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>18.2033</td>\n",
       "      <td>04-01-1999</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1999-01-05</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>29.6912</td>\n",
       "      <td>05-01-1999</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>January</td>\n",
       "      <td>11.4879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1999-01-05</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>29.6912</td>\n",
       "      <td>05-01-1999</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>January</td>\n",
       "      <td>11.4879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1999-01-07</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>32.5205</td>\n",
       "      <td>07-01-1999</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>January</td>\n",
       "      <td>7.3535</td>\n",
       "      <td>14.3172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1999-01-11</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>36.8411</td>\n",
       "      <td>11-01-1999</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "      <td>3.6115</td>\n",
       "      <td>11.6741</td>\n",
       "      <td>18.6378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>6478</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>6479</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>6480</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>6481</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>6482</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index       Date Symbol  Indexvalue  Date_merge day_of_week    month  \\\n",
       "0        0 1999-01-04   V2TX     18.2033  04-01-1999      Monday  January   \n",
       "1        1 1999-01-05   V2TX     29.6912  05-01-1999     Tuesday  January   \n",
       "2        2 1999-01-05   V2TX     29.6912  05-01-1999     Tuesday  January   \n",
       "3        4 1999-01-07   V2TX     32.5205  07-01-1999    Thursday  January   \n",
       "4        6 1999-01-11   V2TX     36.8411  11-01-1999      Monday  January   \n",
       "..     ...        ...    ...         ...         ...         ...      ...   \n",
       "415   6478        NaT    NaN         NaN         NaN         NaN      NaN   \n",
       "416   6479        NaT    NaN         NaN         NaN         NaN      NaN   \n",
       "417   6480        NaT    NaN         NaN         NaN         NaN      NaN   \n",
       "418   6481        NaT    NaN         NaN         NaN         NaN      NaN   \n",
       "419   6482        NaT    NaN         NaN         NaN         NaN      NaN   \n",
       "\n",
       "     delta_daily  delta_3d  delta_5d  ...  sentiment_neutral  \\\n",
       "0            NaN       NaN       NaN  ...                1.0   \n",
       "1        11.4879       NaN       NaN  ...                0.0   \n",
       "2        11.4879       NaN       NaN  ...                1.0   \n",
       "3         7.3535   14.3172       NaN  ...                1.0   \n",
       "4         3.6115   11.6741   18.6378  ...                0.0   \n",
       "..           ...       ...       ...  ...                ...   \n",
       "415          NaN       NaN       NaN  ...                1.0   \n",
       "416          NaN       NaN       NaN  ...                1.0   \n",
       "417          NaN       NaN       NaN  ...                1.0   \n",
       "418          NaN       NaN       NaN  ...                1.0   \n",
       "419          NaN       NaN       NaN  ...                1.0   \n",
       "\n",
       "     sentiment_positive bond_price b_delta_daily  b_delta_3d  b_delta_5d  \\\n",
       "0                   0.0        NaN           NaN         NaN         NaN   \n",
       "1                   0.0        NaN           NaN         NaN         NaN   \n",
       "2                   0.0        NaN           NaN         NaN         NaN   \n",
       "3                   0.0        NaN           NaN         NaN         NaN   \n",
       "4                   0.0        NaN           NaN         NaN         NaN   \n",
       "..                  ...        ...           ...         ...         ...   \n",
       "415                 0.0        NaN           NaN         NaN         NaN   \n",
       "416                 0.0        NaN           NaN         NaN         NaN   \n",
       "417                 0.0        NaN           NaN         NaN         NaN   \n",
       "418                 0.0        NaN           NaN         NaN         NaN   \n",
       "419                 0.0        NaN           NaN         NaN         NaN   \n",
       "\n",
       "     b_delta_30d  b_3d_pp_change  b_delta_3d_pct_lag  delta_3d_pct_lag  \n",
       "0            NaN             NaN                 NaN               NaN  \n",
       "1            NaN             NaN                 NaN               NaN  \n",
       "2            NaN             NaN                 NaN               NaN  \n",
       "3            NaN             NaN                 NaN               NaN  \n",
       "4            NaN             NaN                 NaN               NaN  \n",
       "..           ...             ...                 ...               ...  \n",
       "415          NaN             NaN                 NaN               NaN  \n",
       "416          NaN             NaN                 NaN               NaN  \n",
       "417          NaN             NaN                 NaN               NaN  \n",
       "418          NaN             NaN                 NaN               NaN  \n",
       "419          NaN             NaN                 NaN               NaN  \n",
       "\n",
       "[420 rows x 26 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data with no nans if column is null\n",
    "restricted_sample = merged_df[merged_df['sentiment'].notnull()]\n",
    "restricted_sample.reset_index(inplace=True)\n",
    "restricted_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Indexvalue</th>\n",
       "      <th>Date_merge</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>delta_daily</th>\n",
       "      <th>delta_3d</th>\n",
       "      <th>delta_5d</th>\n",
       "      <th>...</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>bond_price</th>\n",
       "      <th>b_delta_daily</th>\n",
       "      <th>b_delta_3d</th>\n",
       "      <th>b_delta_5d</th>\n",
       "      <th>b_delta_30d</th>\n",
       "      <th>b_3d_pp_change</th>\n",
       "      <th>b_delta_3d_pct_lag</th>\n",
       "      <th>delta_3d_pct_lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>6463</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>6464</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>6465</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>6466</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>6467</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>6468</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>6469</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>6470</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>6471</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>6472</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>6473</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>6474</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>6475</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>6476</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>6477</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>6478</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>6479</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>6480</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>6481</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>6482</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index Date Symbol  Indexvalue Date_merge day_of_week month  delta_daily  \\\n",
       "400   6463  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "401   6464  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "402   6465  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "403   6466  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "404   6467  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "405   6468  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "406   6469  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "407   6470  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "408   6471  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "409   6472  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "410   6473  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "411   6474  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "412   6475  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "413   6476  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "414   6477  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "415   6478  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "416   6479  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "417   6480  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "418   6481  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "419   6482  NaT    NaN         NaN        NaN         NaN   NaN          NaN   \n",
       "\n",
       "     delta_3d  delta_5d  ...  sentiment_neutral  sentiment_positive  \\\n",
       "400       NaN       NaN  ...                1.0                 0.0   \n",
       "401       NaN       NaN  ...                1.0                 0.0   \n",
       "402       NaN       NaN  ...                1.0                 0.0   \n",
       "403       NaN       NaN  ...                1.0                 0.0   \n",
       "404       NaN       NaN  ...                1.0                 0.0   \n",
       "405       NaN       NaN  ...                1.0                 0.0   \n",
       "406       NaN       NaN  ...                0.0                 1.0   \n",
       "407       NaN       NaN  ...                1.0                 0.0   \n",
       "408       NaN       NaN  ...                0.0                 1.0   \n",
       "409       NaN       NaN  ...                1.0                 0.0   \n",
       "410       NaN       NaN  ...                0.0                 0.0   \n",
       "411       NaN       NaN  ...                1.0                 0.0   \n",
       "412       NaN       NaN  ...                1.0                 0.0   \n",
       "413       NaN       NaN  ...                1.0                 0.0   \n",
       "414       NaN       NaN  ...                1.0                 0.0   \n",
       "415       NaN       NaN  ...                1.0                 0.0   \n",
       "416       NaN       NaN  ...                1.0                 0.0   \n",
       "417       NaN       NaN  ...                1.0                 0.0   \n",
       "418       NaN       NaN  ...                1.0                 0.0   \n",
       "419       NaN       NaN  ...                1.0                 0.0   \n",
       "\n",
       "    bond_price b_delta_daily  b_delta_3d  b_delta_5d  b_delta_30d  \\\n",
       "400        NaN           NaN         NaN         NaN          NaN   \n",
       "401        NaN           NaN         NaN         NaN          NaN   \n",
       "402        NaN           NaN         NaN         NaN          NaN   \n",
       "403        NaN           NaN         NaN         NaN          NaN   \n",
       "404        NaN           NaN         NaN         NaN          NaN   \n",
       "405        NaN           NaN         NaN         NaN          NaN   \n",
       "406        NaN           NaN         NaN         NaN          NaN   \n",
       "407        NaN           NaN         NaN         NaN          NaN   \n",
       "408        NaN           NaN         NaN         NaN          NaN   \n",
       "409        NaN           NaN         NaN         NaN          NaN   \n",
       "410        NaN           NaN         NaN         NaN          NaN   \n",
       "411        NaN           NaN         NaN         NaN          NaN   \n",
       "412        NaN           NaN         NaN         NaN          NaN   \n",
       "413        NaN           NaN         NaN         NaN          NaN   \n",
       "414        NaN           NaN         NaN         NaN          NaN   \n",
       "415        NaN           NaN         NaN         NaN          NaN   \n",
       "416        NaN           NaN         NaN         NaN          NaN   \n",
       "417        NaN           NaN         NaN         NaN          NaN   \n",
       "418        NaN           NaN         NaN         NaN          NaN   \n",
       "419        NaN           NaN         NaN         NaN          NaN   \n",
       "\n",
       "     b_3d_pp_change  b_delta_3d_pct_lag  delta_3d_pct_lag  \n",
       "400             NaN                 NaN               NaN  \n",
       "401             NaN                 NaN               NaN  \n",
       "402             NaN                 NaN               NaN  \n",
       "403             NaN                 NaN               NaN  \n",
       "404             NaN                 NaN               NaN  \n",
       "405             NaN                 NaN               NaN  \n",
       "406             NaN                 NaN               NaN  \n",
       "407             NaN                 NaN               NaN  \n",
       "408             NaN                 NaN               NaN  \n",
       "409             NaN                 NaN               NaN  \n",
       "410             NaN                 NaN               NaN  \n",
       "411             NaN                 NaN               NaN  \n",
       "412             NaN                 NaN               NaN  \n",
       "413             NaN                 NaN               NaN  \n",
       "414             NaN                 NaN               NaN  \n",
       "415             NaN                 NaN               NaN  \n",
       "416             NaN                 NaN               NaN  \n",
       "417             NaN                 NaN               NaN  \n",
       "418             NaN                 NaN               NaN  \n",
       "419             NaN                 NaN               NaN  \n",
       "\n",
       "[20 rows x 26 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restricted_sample.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       delta_3d_pct_lag   R-squared:                       0.004\n",
      "Model:                            OLS   Adj. R-squared:                 -0.004\n",
      "Method:                 Least Squares   F-statistic:                    0.4566\n",
      "Date:                Wed, 23 Aug 2023   Prob (F-statistic):              0.713\n",
      "Time:                        12:25:40   Log-Likelihood:                 256.86\n",
      "No. Observations:                 377   AIC:                            -505.7\n",
      "Df Residuals:                     373   BIC:                            -490.0\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================================\n",
      "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Intercept                             -0.0207      0.054     -0.383      0.702      -0.127       0.086\n",
      "sentiment_score                        0.0398      0.065      0.615      0.539      -0.088       0.167\n",
      "sentiment_negative                     0.1181      0.102      1.154      0.249      -0.083       0.319\n",
      "sentiment_score:sentiment_negative    -0.1417      0.121     -1.170      0.243      -0.380       0.096\n",
      "==============================================================================\n",
      "Omnibus:                      151.782   Durbin-Watson:                   1.130\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              765.783\n",
      "Skew:                           1.658   Prob(JB):                    5.16e-167\n",
      "Kurtosis:                       9.145   Cond. No.                         35.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# run olx regression\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Define the regression formula\n",
    "formula = \"delta_3d_pct_lag ~ sentiment_score * sentiment_negative \"\n",
    "\n",
    "# Fit the regression\n",
    "model = smf.ols(formula=formula, data=restricted_sample).fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing FinBERT again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Lehman's bankruptcy reverberated through global markets as its complex positions were unwound and investors worried which financial institutions could be next to fall. Within days, the insurer AIG and savings bank Washington Mutual were in trouble and the US government scrambled to put together a $700bn banking bailout package\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "sentiment = pipe(text)\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative', 'score': 0.9238168597221375}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot daily change in index over time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot the daily change in the index and sentiment score\n",
    "sns.lineplot(data=standardized, x=\"date\", y=\"delta_daily\", label=\"Delta Daily\")\n",
    "#sns.lineplot(data=standardized, x=\"date\", y=\"sentiment_negative\", label=\"Sentiment Negative\")\n",
    "#sns.lineplot(data=standardized, x=\"date\", y=\"sentiment_positive\", label=\"Sentiment Positive\")\n",
    "#sns.lineplot(data=standardized, x=\"date\", y=\"sentiment_neutral\", label=\"Sentiment Neutral\")\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title(\"Daily change in the VSTOXX index\")\n",
    "plt.xlabel(\"Date\")\n",
    "\n",
    "# Rotate the x-axis labels\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
